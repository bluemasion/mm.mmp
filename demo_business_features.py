#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ¼”ç¤ºä¸šåŠ¡æ•°æ®ç®¡ç†åŠŸèƒ½
æµ‹è¯•å­—æ®µæ˜ å°„ã€æ–‡ä»¶å­˜å‚¨å’Œæ•°æ®è¿ç§»åŠŸèƒ½
"""

import os
import sys
sys.path.append('.')

from app.business_data_manager import BusinessDataManager
import pandas as pd
import json
import uuid
from datetime import datetime

def demo_business_data_features():
    """æ¼”ç¤ºä¸šåŠ¡æ•°æ®ç®¡ç†åŠŸèƒ½"""
    
    print("=" * 80)
    print("  MMPä¸šåŠ¡æ•°æ®ç®¡ç†åŠŸèƒ½æ¼”ç¤º")
    print("=" * 80)
    
    # åˆå§‹åŒ–ä¸šåŠ¡æ•°æ®ç®¡ç†å™¨
    project_root = os.path.dirname(os.path.abspath(__file__))
    db_path = os.path.join(project_root, 'business_data.db')
    
    business_manager = BusinessDataManager(db_path)
    print(f"âœ… ä¸šåŠ¡æ•°æ®ç®¡ç†å™¨åˆå§‹åŒ–å®Œæˆ: {db_path}")
    
    # === 1. å­—æ®µæ˜ å°„æ¼”ç¤º ===
    print("\n" + "="*60)
    print("1. å­—æ®µæ˜ å°„åŠŸèƒ½æ¼”ç¤º")
    print("="*60)
    
    # è·å–ç°æœ‰å­—æ®µæ˜ å°„
    mappings = business_manager.get_field_mappings('standard_medical_mapping')
    print(f"ğŸ“‹ å½“å‰å­—æ®µæ˜ å°„æ•°é‡: {len(mappings)}")
    
    print("ğŸ”„ å­—æ®µæ˜ å°„åˆ—è¡¨:")
    for mapping in mappings:
        print(f"  {mapping['source_field']:12} -> {mapping['target_field']:12} ({mapping['field_type']})")
    
    # è·å–æ˜ å°„å­—å…¸
    mapping_dict = business_manager.get_field_mapping_dict('standard_medical_mapping')
    print(f"\nğŸ—‚ï¸  æ˜ å°„å­—å…¸: {mapping_dict}")
    
    # === 2. æ¨¡æ‹Ÿæ–‡ä»¶ä¸Šä¼ å’Œå­˜å‚¨ ===
    print("\n" + "="*60)
    print("2. æ–‡ä»¶æ•°æ®å­˜å‚¨æ¼”ç¤º")
    print("="*60)
    
    # åˆ›å»ºæ¨¡æ‹Ÿæ•°æ®
    sample_data = {
        'èµ„äº§ä»£ç ': ['A001', 'A002', 'A003', 'A004', 'A005'],
        'èµ„äº§åç§°': ['åŒ»ç”¨å£ç½©', 'ä¸€æ¬¡æ€§æ‰‹å¥—', 'ä½“æ¸©è®¡', 'è¡€å‹è®¡', 'å¬è¯Šå™¨'],
        'è§„æ ¼å‹å·': ['N95å‹', 'ä¹³èƒ¶Lç ', 'ç”µå­å¼', 'è‡‚å¼', 'åŒå¤´å¼'],
        'å“ç‰Œ': ['3M', 'å®‰æ€å°”', 'æ¬§å§†é¾™', 'é±¼è·ƒ', 'åˆ©å¾—æ›¼'],
        'åŒ»ä¿ç ': ['YB001', 'YB002', 'YB003', 'YB004', 'YB005'],
        'ç”Ÿäº§å‚å®¶åç§°': ['3Må…¬å¸', 'å®‰æ€å°”å…¬å¸', 'æ¬§å§†é¾™å…¬å¸', 'é±¼è·ƒç§‘æŠ€', 'åˆ©å¾—æ›¼å…¬å¸']
    }
    
    df = pd.DataFrame(sample_data)
    print("ğŸ“„ æ¨¡æ‹Ÿä¸Šä¼ æ•°æ®:")
    print(df.to_string(index=False))
    
    # åº”ç”¨å­—æ®µæ˜ å°„
    mapped_df = df.copy()
    if mapping_dict:
        rename_dict = {}
        for col in mapped_df.columns:
            if col in mapping_dict:
                rename_dict[col] = mapping_dict[col]
        
        if rename_dict:
            mapped_df = mapped_df.rename(columns=rename_dict)
            print(f"\nğŸ”„ åº”ç”¨å­—æ®µæ˜ å°„: {rename_dict}")
            
    print("\nğŸ“‹ æ˜ å°„åæ•°æ®:")
    print(mapped_df.to_string(index=False))
    
    # å­˜å‚¨åˆ°æ•°æ®åº“
    file_id = str(uuid.uuid4())
    session_id = str(uuid.uuid4())
    
    success = business_manager.store_uploaded_file(
        file_id=file_id,
        original_filename='demo_data.xlsx',
        stored_filename=f'{datetime.now().strftime("%Y%m%d_%H%M%S")}_demo_data.xlsx',
        file_size=1024,
        file_type='xlsx',
        session_id=session_id,
        df=mapped_df
    )
    
    if success:
        print(f"\nâœ… æ–‡ä»¶æ•°æ®å­˜å‚¨æˆåŠŸ: file_id = {file_id}")
        
        # è·å–æ–‡ä»¶ä¿¡æ¯
        file_info = business_manager.get_uploaded_file_info(file_id)
        print(f"ğŸ“Š æ–‡ä»¶ä¿¡æ¯: {file_info['row_count']} è¡Œ, {file_info['column_count']} åˆ—")
        
        # è·å–æ–‡ä»¶æ•°æ®
        file_data = business_manager.get_file_data(file_id, limit=3)
        print(f"ğŸ“– å‰3è¡Œæ•°æ®é¢„è§ˆ:")
        for i, row in enumerate(file_data):
            row_without_index = {k: v for k, v in row.items() if k != '_row_index'}
            print(f"  è¡Œ{i+1}: {row_without_index}")
    else:
        print("âŒ æ–‡ä»¶æ•°æ®å­˜å‚¨å¤±è´¥")
    
    # === 3. å¤„ç†ç»“æœå­˜å‚¨æ¼”ç¤º ===
    print("\n" + "="*60)
    print("3. å¤„ç†ç»“æœå­˜å‚¨æ¼”ç¤º")
    print("="*60)
    
    # æ¨¡æ‹Ÿåˆ†ç±»å¤„ç†ç»“æœ
    for i, (_, row) in enumerate(mapped_df.iterrows()):
        input_data = row.to_dict()
        result_data = {
            'classification': 'åŒ»ç–—å™¨æ¢°',
            'category': f'CAT{str(i+1).zfill(3)}',
            'confidence': 0.85 + i * 0.02,
            'matched_rules': ['è§„æ ¼åŒ¹é…', 'å“ç‰ŒåŒ¹é…']
        }
        
        result_id = business_manager.store_processing_result(
            session_id=session_id,
            file_id=file_id,
            result_type='classification',
            row_index=i,
            input_data=input_data,
            result_data=result_data,
            confidence=result_data['confidence'],
            processing_time=0.15 + i * 0.02
        )
        
    print(f"âœ… å­˜å‚¨äº† {len(mapped_df)} ä¸ªåˆ†ç±»ç»“æœ")
    
    # è·å–å¤„ç†ç»“æœ
    results = business_manager.get_processing_results(session_id, 'classification')
    print(f"ğŸ“Š è·å–å¤„ç†ç»“æœ: {len(results)} æ¡")
    
    if results:
        print("ğŸ¯ å¤„ç†ç»“æœç¤ºä¾‹:")
        for result in results[:2]:
            print(f"  è¡Œ{result['row_index']}: {result['result_data']['classification']} -> {result['result_data']['category']} (ç½®ä¿¡åº¦: {result['confidence']})")
    
    # === 4. ç³»ç»Ÿé…ç½®æ¼”ç¤º ===
    print("\n" + "="*60)
    print("4. ç³»ç»Ÿé…ç½®ç®¡ç†æ¼”ç¤º")
    print("="*60)
    
    # è®¾ç½®ä¸€äº›æµ‹è¯•é…ç½®
    test_configs = [
        ('demo_threshold', 0.75, 'number', 'æ¼”ç¤ºé˜ˆå€¼é…ç½®'),
        ('demo_enabled', True, 'boolean', 'æ¼”ç¤ºå¼€å…³é…ç½®'),
        ('demo_settings', {'max_items': 100, 'timeout': 30}, 'json', 'æ¼”ç¤ºJSONé…ç½®')
    ]
    
    for key, value, config_type, desc in test_configs:
        business_manager.set_config(key, value, config_type, desc)
        retrieved_value = business_manager.get_config(key)
        print(f"âš™ï¸  {key}: {value} -> {retrieved_value} ({config_type})")
    
    # === 5. ç»Ÿè®¡ä¿¡æ¯æ¼”ç¤º ===
    print("\n" + "="*60)
    print("5. ç³»ç»Ÿç»Ÿè®¡ä¿¡æ¯")
    print("="*60)
    
    stats = business_manager.get_statistics()
    print("ğŸ“ˆ ç³»ç»Ÿç»Ÿè®¡:")
    for key, value in stats.items():
        print(f"  {key}: {value}")
    
    # === 6. å­—æ®µæ˜ å°„è§£å†³æ–¹æ¡ˆæ¼”ç¤º ===
    print("\n" + "="*80)
    print("ğŸ¯ å­—æ®µæ˜ å°„é—®é¢˜è§£å†³æ–¹æ¡ˆæ¼”ç¤º")
    print("="*80)
    
    print("âŒ åŸå§‹é—®é¢˜:")
    print("   - é…ç½®æ–‡ä»¶å®šä¹‰: 'åŒ»ä¿ä»£ç '")
    print("   - å®é™…ä¸Šä¼ æ–‡ä»¶: 'åŒ»ä¿ç '")
    print("   - å¯¼è‡´å­—æ®µä¸åŒ¹é…é”™è¯¯")
    
    print("\nâœ… è§£å†³æ–¹æ¡ˆ:")
    print("   - æ•°æ®åº“å­˜å‚¨å­—æ®µæ˜ å°„è§„åˆ™")
    print("   - è‡ªåŠ¨å°† 'åŒ»ä¿ç ' æ˜ å°„ä¸º 'åŒ»ä¿ä»£ç '")
    print("   - æ”¯æŒå¤šç§æ˜ å°„é…ç½®æ–¹æ¡ˆ")
    print("   - å¯åŠ¨æ€æ·»åŠ æ–°çš„å­—æ®µæ˜ å°„")
    
    print("\nğŸ”„ æ˜ å°„è½¬æ¢ç¤ºä¾‹:")
    original_fields = ['èµ„äº§ä»£ç ', 'èµ„äº§åç§°', 'è§„æ ¼å‹å·', 'å“ç‰Œ', 'åŒ»ä¿ç ', 'ç”Ÿäº§å‚å®¶åç§°']
    mapped_fields = [mapping_dict.get(field, field) for field in original_fields]
    
    for orig, mapped in zip(original_fields, mapped_fields):
        if orig != mapped:
            print(f"   {orig} -> {mapped}")
        else:
            print(f"   {orig} (æ— éœ€æ˜ å°„)")
    
    print("\n" + "="*80)
    print("âœ… ä¸šåŠ¡æ•°æ®ç®¡ç†åŠŸèƒ½æ¼”ç¤ºå®Œæˆ!")
    print("="*80)
    
    return {
        'file_id': file_id,
        'session_id': session_id,
        'mappings_count': len(mappings),
        'results_count': len(results),
        'statistics': stats
    }

if __name__ == "__main__":
    try:
        demo_results = demo_business_data_features()
        print(f"\nğŸ“‹ æ¼”ç¤ºç»“æœæ±‡æ€»:")
        print(f"  - æ–‡ä»¶ID: {demo_results['file_id']}")
        print(f"  - ä¼šè¯ID: {demo_results['session_id']}")
        print(f"  - å­—æ®µæ˜ å°„: {demo_results['mappings_count']} ä¸ª")
        print(f"  - å¤„ç†ç»“æœ: {demo_results['results_count']} æ¡")
        
    except Exception as e:
        print(f"âŒ æ¼”ç¤ºå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()