#!/usr/bin/env python3
# -*- coding: utf-8 -*-
# project_context_generator.py
"""
é¡¹ç›®ä¸Šä¸‹æ–‡å¿«ç…§ç”Ÿæˆå™¨
ä¸ºå¤§è¯­è¨€æ¨¡å‹å¤šè½®ä¼šè¯æä¾›å®Œæ•´çš„é¡¹ç›®ç†è§£ä¸Šä¸‹æ–‡
"""
import os
import ast
import json
import sqlite3
from datetime import datetime
import glob
import sys
import platform

class ProjectContextGenerator:
    """é¡¹ç›®ä¸Šä¸‹æ–‡ç”Ÿæˆå™¨"""
    
    def __init__(self, project_root="."):
        self.project_root = project_root
        self.context_data = {}
        
    def generate_full_context(self):
        """ç”Ÿæˆå®Œæ•´çš„é¡¹ç›®ä¸Šä¸‹æ–‡å¿«ç…§"""
        print("ğŸ”„ ç”Ÿæˆé¡¹ç›®ä¸Šä¸‹æ–‡å¿«ç…§...")
        
        context = {
            "metadata": {
                "generated_at": datetime.now().isoformat(),
                "project_root": os.path.abspath(self.project_root),
                "generator_version": "1.0"
            }
        }
        
        print("ğŸ æ”¶é›†ç¯å¢ƒä¿¡æ¯...")
        context["environment"] = self._collect_environment_info()
        
        print("ğŸ“š åŠ è½½æ ¸å¿ƒæ–‡æ¡£...")
        context["documents"] = self._load_core_documents()
        
        print("ğŸ—ï¸ åˆ†æä»£ç ç»“æ„...")
        context["code_structure"] = self._analyze_code_structure()
        
        print("ğŸ’¾ åˆ†ææ•°æ®åº“ç»“æ„...")
        context["database_structure"] = self._analyze_database_schema()
        
        print("ğŸ“Š æ”¶é›†é¡¹ç›®ç»Ÿè®¡...")
        context["project_stats"] = self._collect_project_statistics()
        
        print("ğŸ” æ£€æµ‹æœ€è¿‘å˜æ›´...")
        context["recent_changes"] = self._detect_recent_changes()
        
        print("ğŸ¯ æ„å»ºå¼€å‘ä¸Šä¸‹æ–‡...")
        context["development_context"] = self._build_development_context()
        
        print("ğŸ¢ åŠ è½½äº§å“éœ€æ±‚...")
        context["product_requirements"] = self._load_product_requirements()
        
        print("ğŸ—ï¸ åŠ è½½æŠ€æœ¯æ¶æ„...")
        context["technical_architecture"] = self._load_technical_architecture()
        
        return context
    
    def _collect_environment_info(self):
        """æ”¶é›†ç¯å¢ƒå’Œä¾èµ–ä¿¡æ¯"""
        env_info = {}
        
        # Pythonç‰ˆæœ¬ä¿¡æ¯
        env_info["python_version"] = {
            "version": sys.version,
            "version_info": "{}.{}.{}".format(*sys.version_info[:3]),
            "executable": sys.executable
        }
        
        # è¯»å–requirements.txt
        if os.path.exists("requirements.txt"):
            try:
                import io
                with io.open("requirements.txt", 'r', encoding='utf-8') as f:
                    requirements_content = f.read()
                    # è§£æä¸»è¦ä¾èµ–
                    main_deps = []
                    for line in requirements_content.split('\n'):
                        line = line.strip()
                        if line and not line.startswith('#') and not line.startswith('-'):
                            if '==' in line or '>=' in line or '<=' in line:
                                main_deps.append(line)
                    env_info["dependencies"] = {
                        "total_requirements": len(main_deps),
                        "main_packages": main_deps[:15],  # æ˜¾ç¤ºå‰15ä¸ªä¸»è¦åŒ…
                        "requirements_file_size": len(requirements_content)
                    }
            except Exception as e:
                env_info["dependencies"] = {"error": "Error reading requirements.txt: " + str(e)}
        else:
            env_info["dependencies"] = {"error": "requirements.txt not found"}
        
        # æ“ä½œç³»ç»Ÿä¿¡æ¯
        env_info["system"] = {
            "platform": platform.platform(),
            "system": platform.system(),
            "architecture": platform.architecture()[0]
        }
        
        return env_info
    
    def _load_core_documents(self):
        """åŠ è½½æ ¸å¿ƒé¡¹ç›®æ–‡æ¡£"""
        documents = {}
        
        # æ ¸å¿ƒæ–‡æ¡£åˆ—è¡¨
        core_docs = [
            "æ™ºèƒ½åˆ†ç±»æ¨èåŠŸèƒ½éœ€æ±‚ä¸ä½¿ç”¨æŒ‡å—.md",
            "ARCHITECTURE_REFACTORING_PLAN.md",
            "DATABASE_ENHANCEMENT_REPORT.md",
            "PROJECT_COMPLETION_SUMMARY.md",
            "README.md"
        ]
        
        for doc in core_docs:
            if os.path.exists(doc):
                try:
                    import io
                    with io.open(doc, 'r', encoding='utf-8') as f:
                        content = f.read()
                        # é™åˆ¶é•¿åº¦é¿å…è¿‡é•¿
                        if len(content) > 2000:
                            content = content[:2000] + "\n..."
                        documents[doc] = content
                except Exception as e:
                    documents[doc] = "Error loading: " + str(e)
        
        return documents
    
    def _analyze_code_structure(self):
        """åˆ†æä»£ç ç»“æ„"""
        structure = {
            "main_modules": [],
            "app_modules": []
        }
        
        # åˆ†æä¸»æ¨¡å—
        for py_file in glob.glob("*.py"):
            analysis = self._analyze_python_file(py_file)
            if analysis:
                structure["main_modules"].append(analysis)
        
        # åˆ†æappæ¨¡å—
        app_dir = os.path.join(self.project_root, "app")
        if os.path.exists(app_dir):
            for py_file in glob.glob(os.path.join(app_dir, "*.py")):
                analysis = self._analyze_python_file(py_file)
                if analysis:
                    structure["app_modules"].append(analysis)
        
        return structure
    
    def _analyze_python_file(self, file_path):
        """åˆ†æå•ä¸ªPythonæ–‡ä»¶"""
        try:
            import io
            with io.open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # è§£æAST
            tree = ast.parse(content)
            
            classes = []
            functions = []
            
            for node in ast.walk(tree):
                if isinstance(node, ast.ClassDef):
                    classes.append(node.name)
                elif isinstance(node, ast.FunctionDef) and node.col_offset == 0:  # åªç»Ÿè®¡é¡¶çº§å‡½æ•°
                    functions.append(node.name)
            
            # è·å–æ¨¡å—æ–‡æ¡£å­—ç¬¦ä¸²
            docstring = ""
            if (tree.body and isinstance(tree.body[0], ast.Expr) 
                and hasattr(tree.body[0].value, 's')):
                docstring = tree.body[0].value.s
            elif (tree.body and isinstance(tree.body[0], ast.Expr)
                  and hasattr(tree.body[0].value, 'value')
                  and isinstance(tree.body[0].value.value, str)):
                docstring = tree.body[0].value.value
            
            lines = len(content.splitlines())
            
            return {
                "name": os.path.basename(file_path),
                "path": file_path,
                "classes": len(classes),
                "functions": len(functions),
                "lines": lines,
                "docstring": docstring.strip() if docstring else ""
            }
        except Exception as e:
            return {
                "name": os.path.basename(file_path),
                "path": file_path,
                "error": str(e)
            }
    
    def _analyze_database_schema(self):
        """åˆ†ææ•°æ®åº“ç»“æ„"""
        databases = {}
        
        # æŸ¥æ‰¾æ‰€æœ‰.dbæ–‡ä»¶
        for db_file in glob.glob("*.db"):
            try:
                conn = sqlite3.connect(db_file)
                cursor = conn.cursor()
                
                # è·å–æ‰€æœ‰è¡¨
                cursor.execute("SELECT name FROM sqlite_master WHERE type='table'")
                tables = cursor.fetchall()
                
                db_info = {}
                for table in tables:
                    table_name = table[0]
                    
                    # è·å–è¡¨ç»“æ„
                    cursor.execute("PRAGMA table_info({})".format(table_name))
                    columns = cursor.fetchall()
                    
                    # è·å–è¡Œæ•°
                    cursor.execute("SELECT COUNT(*) FROM {}".format(table_name))
                    row_count = cursor.fetchone()[0]
                    
                    db_info[table_name] = {
                        "columns": len(columns),
                        "rows": row_count
                    }
                
                databases[db_file] = db_info
                conn.close()
                
            except Exception as e:
                databases[db_file] = {"error": str(e)}
        
        return databases
    
    def _collect_project_statistics(self):
        """æ”¶é›†é¡¹ç›®ç»Ÿè®¡ä¿¡æ¯"""
        stats = {
            "file_counts": {},
            "code_metrics": {
                "python_files": 0,
                "total_lines": 0,
                "total_classes": 0,
                "total_functions": 0
            }
        }
        
        # ç»Ÿè®¡æ–‡ä»¶ç±»å‹
        for root, dirs, files in os.walk(self.project_root):
            for file in files:
                ext = os.path.splitext(file)[1]
                if ext:
                    stats["file_counts"][ext] = stats["file_counts"].get(ext, 0) + 1
        
        # ç»Ÿè®¡Pythonä»£ç æŒ‡æ ‡
        for py_file in glob.glob("*.py") + glob.glob("app/*.py"):
            if os.path.exists(py_file):
                analysis = self._analyze_python_file(py_file)
                if "error" not in analysis:
                    stats["code_metrics"]["python_files"] += 1
                    stats["code_metrics"]["total_lines"] += analysis.get("lines", 0)
                    stats["code_metrics"]["total_classes"] += analysis.get("classes", 0)
                    stats["code_metrics"]["total_functions"] += analysis.get("functions", 0)
        
        return stats
    
    def _detect_recent_changes(self):
        """æ£€æµ‹æœ€è¿‘çš„æ–‡ä»¶å˜æ›´"""
        changes = []
        
        # è·å–æœ€è¿‘ä¿®æ”¹çš„æ–‡ä»¶
        all_files = []
        for root, dirs, files in os.walk(self.project_root):
            for file in files:
                if not file.startswith('.') and file.endswith(('.py', '.md', '.json', '.yml', '.yaml')):
                    file_path = os.path.join(root, file)
                    try:
                        mtime = os.path.getmtime(file_path)
                        all_files.append((file_path, mtime))
                    except OSError:
                        pass
        
        # æŒ‰ä¿®æ”¹æ—¶é—´æ’åºï¼Œå–æœ€è¿‘10ä¸ª
        all_files.sort(key=lambda x: x[1], reverse=True)
        recent_files = all_files[:10]
        
        for file_path, mtime in recent_files:
            changes.append({
                "file": os.path.relpath(file_path, self.project_root),
                "modified": datetime.fromtimestamp(mtime).isoformat()
            })
        
        return changes
    
    def _build_development_context(self):
        """æ„å»ºå¼€å‘ä¸Šä¸‹æ–‡ä¿¡æ¯"""
        context = {
            "main_features": [
                "æ™ºèƒ½åˆ†ç±»æ¨è",
                "å¤šæºèåˆåŒ¹é…ï¼ˆå…³é”®è¯ã€åˆ¶é€ å•†ã€è§„æ ¼æ¨¡å¼ï¼‰",
                "TF-IDFç›¸ä¼¼åº¦è®¡ç®—",
                "è®­ç»ƒæ•°æ®ç®¡ç†",
                "Webç•Œé¢"
            ],
            "known_issues": [
                "åˆ†ç±»ä½“ç³»éœ€æŒç»­æ‰©å±•",
                "è®­ç»ƒæ•°æ®éœ€å®šæœŸæ›´æ–°",
                "ä¸Šä¸‹æ–‡å¿«ç…§æœºåˆ¶éœ€å®Œå–„"
            ],
            "next_steps": [
                "å®Œå–„ä¸Šä¸‹æ–‡å¿«ç…§ç³»ç»Ÿ",
                "ä¼˜åŒ–åˆ†ç±»ç®—æ³•å‡†ç¡®ç‡", 
                "æ‰©å±•å¤šè¯­è¨€æ”¯æŒ"
            ]
        }
        
        return context
    
    def _load_product_requirements(self):
        """åŠ è½½äº§å“éœ€æ±‚å’Œä¸šåŠ¡èƒŒæ™¯"""
        requirements = {
            "core_business_problem": {
                "title": "è·¨ç³»ç»Ÿç‰©æ–™æ•°æ®æ™ºèƒ½å¯¹ç ",
                "description": "è§£å†³é›†å›¢ä¸äºŒçº§å…¬å¸ã€ä¸åŒä¸šåŠ¡ç³»ç»Ÿé—´ç‰©æ–™ä¸»æ•°æ®ä¸ä¸€è‡´é—®é¢˜",
                "pain_points": [
                    "å‘½åã€ç¼–ç ä½“ç³»ä¸ä¸€è‡´ï¼Œå¯¼è‡´é‡å¤å»ºç å’Œè·¨ç³»ç»Ÿæ•°æ®æ— æ³•ç»Ÿä¸€",
                    "äººå·¥å½•å…¥æ•ˆç‡ä½ã€æ˜“å‡ºé”™ï¼Œå®¡æ ¸æˆæœ¬é«˜", 
                    "ç¼ºä¹æ™ºèƒ½æ¸…æ´—ä¸å¯¹ç èƒ½åŠ›ï¼Œå†å²æ•°æ®è´¨é‡å‚å·®ä¸é½"
                ]
            },
            "target_goals": {
                "efficiency": "ç‰©æ–™ç”³è¯·æ•ˆç‡æå‡50%ä»¥ä¸Š",
                "duplicate_reduction": "é‡å¤å»ºç ç‡é™ä½80%", 
                "matching_performance": {
                    "recall_rate": "â‰¥95%",
                    "precision_rate": "â‰¥90%"
                },
                "data_quality": "å±æ€§ç¼ºå¤±ç‡é™ä½70%"
            },
            "key_features": {
                "intelligent_matching": {
                    "description": "æ™ºèƒ½å¯¹ç ï¼ˆæ ¸å¿ƒåŠŸèƒ½ï¼‰",
                    "scenarios": "é›†å›¢ä¸»æ•°æ®ä¸ä¼ä¸šä¸»æ•°æ®ã€è·¨ä¸šåŠ¡ç³»ç»Ÿç‰©æ–™å¯¹ç ",
                    "technical_approach": "NLP + æ·±åº¦å­¦ä¹  + ç›¸ä¼¼åº¦è®¡ç®—"
                },
                "data_standardization": {
                    "description": "ç‰©æ–™ä¸»æ•°æ®ç”³è¯·ä¸æ¸…æ´—",
                    "capabilities": [
                        "è‡ªåŠ¨æå–ç‰©æ–™ä¿¡æ¯ï¼ˆExcelã€ç³»ç»Ÿã€å›¾çº¸ã€é“­ç‰Œç­‰ï¼‰",
                        "å…³é”®å‚æ•°æå–ï¼ˆåˆ†è¯/NLPï¼‰",
                        "è‡ªåŠ¨æ¨èåˆ†ç±»ï¼ˆå¤šçº§åˆ†ç±»ä½“ç³»ï¼‰",
                        "æ¨¡ç³ŠåŒ¹é…é¿å…é‡å¤å»ºç "
                    ]
                },
                "multi_source_integration": {
                    "description": "å¤šæ•°æ®æºçµæ´»å¯¹æ¥",
                    "supported_sources": [
                        "æ–‡ä»¶ä¸Šä¼ ï¼ˆCSV/Excel/JSONï¼‰",
                        "æ•°æ®åº“å¯¹æ¥ï¼ˆSQLæŸ¥è¯¢ï¼‰", 
                        "APIæ¥å£ï¼ˆREST/GraphQLï¼‰"
                    ],
                    "field_mapping": "æ”¯æŒçµæ´»å­—æ®µæ˜ å°„å’Œæ¨¡æ¿ç®¡ç†"
                }
            }
        }
        return requirements
    
    def _load_technical_architecture(self):
        """åŠ è½½æŠ€æœ¯æ¶æ„è®¾è®¡"""
        architecture = {
            "system_overview": {
                "name": "MMPæ™ºèƒ½ç‰©æ–™ä¸»æ•°æ®ç®¡ç†å¹³å°",
                "version": "v2.0 (æ•°æ®åº“å¢å¼ºç‰ˆ)",
                "core_technologies": ["Python 3.8", "Flask", "SQLite", "TF-IDF", "Faiss", "scikit-learn"]
            },
            "architecture_layers": {
                "data_source_layer": {
                    "description": "å¤šæ•°æ®æºæ¥å…¥å±‚",
                    "components": [
                        "FileAdapter (CSV/Excel/JSON)",
                        "DatabaseAdapter (SQLite/MySQL/PostgreSQL)",
                        "APIAdapter (REST/GraphQL)"
                    ]
                },
                "algorithm_layer": {
                    "description": "æ™ºèƒ½å¯¹ç ç®—æ³•å±‚",
                    "strategies": [
                        "ExactMatch (ç²¾ç¡®åŒ¹é…ï¼šæ ‡å‡†ç¼–ç )",
                        "TextSimilarity (æ–‡æœ¬ç›¸ä¼¼åº¦ï¼šTF-IDF/BERT)",
                        "SpecPattern (è§„æ ¼æ¨¡å¼ï¼šæ­£åˆ™/NLP)",
                        "ManufacturerMatch (åˆ¶é€ å•†åŒ¹é…ï¼šå“ç‰Œæ ‡å‡†åŒ–)"
                    ]
                }
            },
            "key_algorithms": {
                "current_implementation": {
                    "text_vectorization": "TF-IDF + Faissç´¢å¼•",
                    "similarity_calculation": "L2è·ç¦»è½¬ç›¸ä¼¼åº¦",
                    "matching_strategy": "åŒ»ä¿ä»£ç ç²¾ç¡®åŒ¹é… + æ–‡æœ¬ç›¸ä¼¼åº¦åŒ¹é…"
                },
                "enhancement_plan": {
                    "embedding_models": "é›†æˆBERT/SBERTé¢„è®­ç»ƒæ¨¡å‹",
                    "multi_feature_weighting": "ç‰©æ–™åç§°+è§„æ ¼+å‚å®¶åŠ æƒèåˆ",
                    "adaptive_thresholds": "åŠ¨æ€é˜ˆå€¼è°ƒèŠ‚å’ŒA/Bæµ‹è¯•"
                }
            }
        }
        return architecture
    
    def save_context_snapshot(self, context, filename=None):
        """ä¿å­˜ä¸Šä¸‹æ–‡å¿«ç…§ä¸ºMarkdownæ–‡ä»¶"""
        if filename is None:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = "PROJECT_CONTEXT_SNAPSHOT_{}.md".format(timestamp)
        
        print("ğŸ’¾ ä¿å­˜ä¸Šä¸‹æ–‡å¿«ç…§åˆ° {}...".format(filename))
        
        markdown_content = self._generate_markdown_context(context)
        
        import io
        with io.open(filename, 'w', encoding='utf-8') as f:
            f.write(markdown_content)
        
        print("âœ… ä¸Šä¸‹æ–‡å¿«ç…§å·²ä¿å­˜: {}".format(filename))
        return filename
    
    def _generate_markdown_context(self, context):
        """ç”ŸæˆMarkdownæ ¼å¼çš„ä¸Šä¸‹æ–‡æ–‡æ¡£"""
        md = []
        
        # æ ‡é¢˜å’Œå…ƒæ•°æ®
        md.append("# MMPé¡¹ç›®ä¸Šä¸‹æ–‡å¿«ç…§")
        md.append("> ç”Ÿæˆæ—¶é—´: " + context['metadata']['generated_at'])
        md.append("> ç”Ÿæˆå™¨ç‰ˆæœ¬: " + context['metadata']['generator_version'])
        md.append("")
        
        # é¡¹ç›®æ¦‚è§ˆ
        md.append("## ğŸ¯ é¡¹ç›®æ¦‚è§ˆ")
        md.append("æ„å»ºåŸºäºæ•°æ®åº“çš„ç‰©æ–™ä¸»æ•°æ®æ™ºèƒ½åˆ†ç±»æ¨èç³»ç»Ÿ")
        md.append("")
        md.append("**å½“å‰é˜¶æ®µ**: æ•°æ®åº“åŒ–å®Œæˆï¼Œæ™ºèƒ½åˆ†ç±»ç³»ç»Ÿä¼˜åŒ–é˜¶æ®µ")
        md.append("")
        md.append("**æ ¸å¿ƒæŠ€æœ¯**: Python, Flask, SQLite, scikit-learn, TF-IDF, jieba")
        md.append("")
        
        # ç¯å¢ƒä¿¡æ¯
        if context.get("environment"):
            env = context["environment"]
            md.append("## ğŸ å¼€å‘ç¯å¢ƒ")
            md.append("")
            
            # Pythonç‰ˆæœ¬
            if env.get("python_version"):
                py_info = env["python_version"]
                md.append("### Pythonç¯å¢ƒ")
                md.append("- **ç‰ˆæœ¬**: " + py_info.get("version_info", "æœªçŸ¥"))
                md.append("- **å®Œæ•´ç‰ˆæœ¬**: " + py_info.get("version", "æœªçŸ¥").replace('\n', ' '))
                md.append("- **æ‰§è¡Œè·¯å¾„**: " + py_info.get("executable", "æœªçŸ¥"))
                md.append("")
            
            # ç³»ç»Ÿä¿¡æ¯
            if env.get("system"):
                sys_info = env["system"]
                md.append("### ç³»ç»Ÿç¯å¢ƒ")
                md.append("- **å¹³å°**: " + sys_info.get("platform", "æœªçŸ¥"))
                md.append("- **ç³»ç»Ÿ**: " + sys_info.get("system", "æœªçŸ¥"))
                md.append("- **æ¶æ„**: " + sys_info.get("architecture", "æœªçŸ¥"))
                md.append("")
            
            # ä¾èµ–ä¿¡æ¯
            if env.get("dependencies"):
                deps = env["dependencies"]
                if "error" not in deps:
                    md.append("### é¡¹ç›®ä¾èµ–")
                    md.append("- **ä¾èµ–åŒ…æ•°é‡**: " + str(deps.get("total_requirements", 0)))
                    md.append("- **requirements.txtå¤§å°**: " + str(deps.get("requirements_file_size", 0)) + " å­—ç¬¦")
                    md.append("")
                    md.append("**ä¸»è¦ä¾èµ–åŒ…:**")
                    for pkg in deps.get("main_packages", []):
                        md.append("- " + pkg)
                    md.append("")
                else:
                    md.append("### ä¾èµ–ä¿¡æ¯")
                    md.append("- **çŠ¶æ€**: " + deps.get("error", "æœªçŸ¥é”™è¯¯"))
                    md.append("")
        
        # æ ¸å¿ƒæ–‡æ¡£æ‘˜è¦
        if context.get("documents"):
            md.append("## ğŸ“š æ ¸å¿ƒæ–‡æ¡£æ‘˜è¦")
            md.append("")
            for doc_name, content in context["documents"].items():
                md.append("### " + doc_name)
                md.append("```")
                md.append(content)
                md.append("```")
                md.append("")
        
        # ä»£ç ç»“æ„æ¦‚è§ˆ
        if context.get("code_structure"):
            md.append("## ğŸ—ï¸ ä»£ç ç»“æ„æ¦‚è§ˆ")
            md.append("")
            
            # ä¸»æ¨¡å—
            main_modules = context["code_structure"].get("main_modules", [])
            if main_modules:
                md.append("### ä¸»æ¨¡å— ({} ä¸ª)".format(len(main_modules)))
                for module in main_modules:
                    line = "- **{}**: {}ä¸ªç±», {}ä¸ªå‡½æ•°, {}è¡Œ".format(
                        module['name'], 
                        module.get('classes', 0), 
                        module.get('functions', 0), 
                        module.get('lines', 0)
                    )
                    md.append(line)
                    if module.get('docstring'):
                        md.append("  > " + module['docstring'])
                md.append("")
            
            # Appæ¨¡å—
            app_modules = context["code_structure"].get("app_modules", [])
            if app_modules:
                md.append("### Appæ¨¡å— ({} ä¸ª)".format(len(app_modules)))
                for module in app_modules:
                    line = "- **{}**: {}ä¸ªç±», {}ä¸ªå‡½æ•°, {}è¡Œ".format(
                        module['name'], 
                        module.get('classes', 0), 
                        module.get('functions', 0), 
                        module.get('lines', 0)
                    )
                    md.append(line)
                    if module.get('docstring'):
                        md.append("  > " + module['docstring'])
                md.append("")
        
        # æ•°æ®åº“ç»“æ„
        if context.get("database_structure"):
            md.append("## ğŸ’¾ æ•°æ®åº“ç»“æ„")
            md.append("")
            for db_name, tables in context["database_structure"].items():
                md.append("### " + db_name)
                if "error" in tables:
                    md.append("- é”™è¯¯: " + tables['error'])
                else:
                    for table_name, info in tables.items():
                        md.append("- **{}**: {}åˆ—, {}è¡Œæ•°æ®".format(
                            table_name, info['columns'], info['rows']
                        ))
                md.append("")
        
        # é¡¹ç›®ç»Ÿè®¡
        if context.get("project_stats"):
            stats = context["project_stats"]
            md.append("## ğŸ“Š é¡¹ç›®ç»Ÿè®¡")
            md.append("")
            
            # æ–‡ä»¶ç»Ÿè®¡
            if stats.get("file_counts"):
                md.append("### æ–‡ä»¶ç»Ÿè®¡")
                for ext, count in stats["file_counts"].items():
                    md.append("- {} æ–‡ä»¶: {} ä¸ª".format(ext, count))
                md.append("")
            
            # ä»£ç åº¦é‡
            if stats.get("code_metrics"):
                metrics = stats["code_metrics"]
                md.append("### ä»£ç åº¦é‡")
                md.append("- Pythonæ–‡ä»¶: {} ä¸ª".format(metrics['python_files']))
                md.append("- æ€»ä»£ç è¡Œæ•°: {} è¡Œ".format(metrics['total_lines']))
                md.append("- ç±»æ€»æ•°: {} ä¸ª  ".format(metrics['total_classes']))
                md.append("- å‡½æ•°æ€»æ•°: {} ä¸ª".format(metrics['total_functions']))
                md.append("")
        
        # æœ€è¿‘å˜æ›´
        if context.get("recent_changes"):
            md.append("## ğŸ”„ æœ€è¿‘å˜æ›´")
            for change in context["recent_changes"]:
                md.append("- {} ({})".format(change['file'], change['modified']))
            md.append("")
        
        # å¼€å‘ä¸Šä¸‹æ–‡
        if context.get("development_context"):
            dev_ctx = context["development_context"]
            md.append("## ğŸ¯ å¼€å‘ä¸Šä¸‹æ–‡")
            md.append("")
            
            md.append("### ä¸»è¦åŠŸèƒ½")
            for feature in dev_ctx.get("main_features", []):
                md.append("- " + feature)
            md.append("")
            
            md.append("### å·²çŸ¥é—®é¢˜")
            for issue in dev_ctx.get("known_issues", []):
                md.append("- " + issue)
            md.append("")
            
            md.append("### ä¸‹ä¸€æ­¥è®¡åˆ’")
            for step in dev_ctx.get("next_steps", []):
                md.append("- " + step)
            md.append("")
        
        # äº§å“éœ€æ±‚
        if context.get("product_requirements"):
            req = context["product_requirements"]
            md.append("## ğŸ¯ äº§å“éœ€æ±‚ä¸ä¸šåŠ¡èƒŒæ™¯")
            md.append("")
            
            # æ ¸å¿ƒé—®é¢˜
            problem = req["core_business_problem"]
            md.append("### æ ¸å¿ƒä¸šåŠ¡é—®é¢˜")
            md.append("**{}**".format(problem["title"]))
            md.append("")
            md.append(problem["description"])
            md.append("")
            md.append("**ä¸»è¦ç—›ç‚¹ï¼š**")
            for pain_point in problem["pain_points"]:
                md.append("- " + pain_point)
            md.append("")
            
            # ç›®æ ‡æŒ‡æ ‡
            goals = req["target_goals"]
            md.append("### ç›®æ ‡æŒ‡æ ‡")
            md.append("- **æ•ˆç‡æå‡**: {}".format(goals["efficiency"]))
            md.append("- **é‡å¤ç‡é™ä½**: {}".format(goals["duplicate_reduction"]))
            md.append("- **å¯¹ç å¬å›ç‡**: {}".format(goals["matching_performance"]["recall_rate"]))
            md.append("- **å¯¹ç å‡†ç¡®ç‡**: {}".format(goals["matching_performance"]["precision_rate"]))
            md.append("- **æ•°æ®è´¨é‡**: {}".format(goals["data_quality"]))
            md.append("")
            
            # å…³é”®åŠŸèƒ½
            features = req["key_features"]
            md.append("### å…³é”®åŠŸèƒ½")
            for feature_key, feature_info in features.items():
                md.append("**{}**".format(feature_info["description"]))
                if "scenarios" in feature_info:
                    md.append("- åº”ç”¨åœºæ™¯: {}".format(feature_info["scenarios"]))
                if "technical_approach" in feature_info:
                    md.append("- æŠ€æœ¯è·¯çº¿: {}".format(feature_info["technical_approach"]))
                if "capabilities" in feature_info:
                    for capability in feature_info["capabilities"]:
                        md.append("- " + capability)
                if "supported_sources" in feature_info:
                    md.append("- æ”¯æŒæ•°æ®æº:")
                    for source in feature_info["supported_sources"]:
                        md.append("  - " + source)
                md.append("")
        
        # æŠ€æœ¯æ¶æ„
        if context.get("technical_architecture"):
            arch = context["technical_architecture"]
            md.append("## ğŸ—ï¸ æŠ€æœ¯æ¶æ„è®¾è®¡")
            md.append("")
            
            # ç³»ç»Ÿæ¦‚è§ˆ
            overview = arch["system_overview"]
            md.append("### ç³»ç»Ÿæ¦‚è§ˆ")
            md.append("- **å¹³å°åç§°**: {}".format(overview["name"]))
            md.append("- **ç‰ˆæœ¬**: {}".format(overview["version"]))
            md.append("- **æ ¸å¿ƒæŠ€æœ¯**: {}".format(", ".join(overview["core_technologies"])))
            md.append("")
            
            # æ¶æ„åˆ†å±‚
            layers = arch["architecture_layers"]
            md.append("### æ¶æ„åˆ†å±‚")
            for layer_name, layer_info in layers.items():
                md.append("**{}**".format(layer_info["description"]))
                if "components" in layer_info:
                    for component in layer_info["components"]:
                        md.append("- " + component)
                if "strategies" in layer_info:
                    for strategy in layer_info["strategies"]:
                        md.append("- " + strategy)
                if "modules" in layer_info:
                    for module in layer_info["modules"]:
                        md.append("- " + module)
                if "features" in layer_info:
                    for feature in layer_info["features"]:
                        md.append("- " + feature)
                md.append("")
            
            # å…³é”®ç®—æ³•
            algorithms = arch["key_algorithms"]
            md.append("### å…³é”®ç®—æ³•")
            md.append("**å½“å‰å®ç°:**")
            current = algorithms["current_implementation"]
            for key, value in current.items():
                md.append("- {}: {}".format(key.replace("_", " ").title(), value))
            md.append("")
            md.append("**æ”¹è¿›è®¡åˆ’:**")
            enhancement = algorithms["enhancement_plan"]
            for key, value in enhancement.items():
                md.append("- {}: {}".format(key.replace("_", " ").title(), value))
            md.append("")
        
        md.append("---")
        md.append("*æ­¤ä¸Šä¸‹æ–‡å¿«ç…§ç”¨äºå¤§è¯­è¨€æ¨¡å‹å¤šè½®ä¼šè¯çš„é¡¹ç›®ç†è§£å’Œå¼€å‘è¿ç»­æ€§ä¿éšœ*")
        
        return "\n".join(md)


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ MMPé¡¹ç›®ä¸Šä¸‹æ–‡å¿«ç…§ç”Ÿæˆå™¨")
    print("=" * 50)
    
    # åˆ›å»ºç”Ÿæˆå™¨å®ä¾‹
    generator = ProjectContextGenerator()
    
    try:
        # ç”Ÿæˆä¸Šä¸‹æ–‡
        context = generator.generate_full_context()
        
        # ä¿å­˜å¿«ç…§
        filename = generator.save_context_snapshot(context)
        
        print("=" * 50)
        print("âœ… é¡¹ç›®ä¸Šä¸‹æ–‡å¿«ç…§ç”Ÿæˆå®Œæˆï¼")
        print("ğŸ“„ æ–‡ä»¶ä½ç½®: {}".format(filename))
        print("ğŸ’¡ æ­¤æ–‡æ¡£å¯ç”¨äºæ–°ä¼šè¯çš„é¡¹ç›®ç†è§£å’Œå¼€å‘è¡”æ¥")
        
    except Exception as e:
        print("âŒ ç”Ÿæˆä¸Šä¸‹æ–‡å¿«ç…§æ—¶å‡ºé”™: {}".format(str(e)))
        return 1
    
    return 0

if __name__ == "__main__":
    import sys
    sys.exit(main())