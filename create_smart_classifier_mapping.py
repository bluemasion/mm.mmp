#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
åŸºäºå®é™…æ•°æ®åº“çš„æ™ºèƒ½åˆ†ç±»æ˜ å°„ä¼˜åŒ–
æ ¹æ®ç°æœ‰çš„548ä¸ªåˆ¶é€ ä¸šåˆ†ç±»ï¼Œé‡æ–°æ„å»ºå…³é”®è¯æ˜ å°„
"""

import sys
import os
import sqlite3
import json
from typing import Dict, List, Any
import logging

# æ·»åŠ é¡¹ç›®è·¯å¾„åˆ°sys.path
current_dir = os.path.dirname(os.path.abspath(__file__))
if current_dir not in sys.path:
    sys.path.insert(0, current_dir)

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def analyze_existing_categories():
    """åˆ†æç°æœ‰æ•°æ®åº“ä¸­çš„åˆ†ç±»æ•°æ®"""
    print("ğŸ” åˆ†æç°æœ‰åˆ†ç±»æ•°æ®...")
    
    try:
        conn = sqlite3.connect('master_data.db')
        cursor = conn.cursor()
        
        # è·å–æ‰€æœ‰åˆ†ç±»
        cursor.execute('''
            SELECT id, category_code, category_name, level, parent_code, parent_name
            FROM material_categories 
            ORDER BY level, category_code
        ''')
        
        categories = cursor.fetchall()
        print(f"æ€»å…±æ‰¾åˆ° {len(categories)} ä¸ªåˆ†ç±»")
        
        # æŒ‰å±‚çº§åˆ†ç»„
        level_groups = {1: [], 2: [], 3: []}
        for category in categories:
            level = category[3]
            if level in level_groups:
                level_groups[level].append({
                    'id': category[0],
                    'code': category[1],
                    'name': category[2],
                    'level': category[3],
                    'parent_code': category[4],
                    'parent_name': category[5]
                })
        
        print("\\nå„å±‚çº§åˆ†ç±»ç»Ÿè®¡:")
        for level, cats in level_groups.items():
            print(f"  Level {level}: {len(cats)} ä¸ª")
            
        conn.close()
        return level_groups
        
    except Exception as e:
        print(f"âŒ åˆ†æå¤±è´¥: {e}")
        return {}

def build_smart_keyword_mappings(categories_by_level):
    """åŸºäºå®é™…åˆ†ç±»æ„å»ºæ™ºèƒ½å…³é”®è¯æ˜ å°„"""
    print("\\nğŸ§  æ„å»ºæ™ºèƒ½å…³é”®è¯æ˜ å°„...")
    
    keyword_mappings = {}
    
    # éå†æ‰€æœ‰åˆ†ç±»ï¼Œä¸ºæ¯ä¸ªåˆ†ç±»ç”Ÿæˆå…³é”®è¯
    for level, categories in categories_by_level.items():
        for category in categories:
            name = category['name']
            keywords = generate_keywords_for_category(name)
            
            if keywords:
                keyword_mappings[name] = keywords
                
    print(f"ç”Ÿæˆäº† {len(keyword_mappings)} ä¸ªåˆ†ç±»çš„å…³é”®è¯æ˜ å°„")
    return keyword_mappings

def generate_keywords_for_category(category_name: str) -> List[str]:
    """ä¸ºå•ä¸ªåˆ†ç±»ç”Ÿæˆå…³é”®è¯"""
    keywords = []
    name_lower = category_name.lower()
    
    # åŸºç¡€å…³é”®è¯ï¼šåˆ†ç±»åç§°æœ¬èº«çš„åˆ†è¯
    base_keywords = [category_name]
    
    # åŒ–å·¥ç›¸å…³åˆ†ç±»çš„å…³é”®è¯
    if any(word in name_lower for word in ['åŒ–å·¥', 'å‚¬åŒ–å‰‚', 'åŠ©å‰‚', 'æº¶å‰‚', 'æ·»åŠ å‰‚']):
        keywords.extend(['åŒ–å·¥', 'åŒ–å­¦', 'å‚¬åŒ–å‰‚', 'åŠ©å‰‚', 'æº¶å‰‚', 'æ·»åŠ å‰‚', 'åŒ–å­¦å“'])
        if 'å‚¬åŒ–å‰‚' in name_lower:
            keywords.extend(['catalyst', 'å‚¬åŒ–', 'è½½ä½“', 'al2o3', 'sio2'])
        if 'åŠ©å‰‚' in name_lower:
            keywords.extend(['æ·»åŠ å‰‚', 'ç¨³å®šå‰‚', 'å¢å¡‘å‰‚', 'æ”¹æ€§å‰‚'])
        if 'æº¶å‰‚' in name_lower:
            keywords.extend(['æº¶æ¶²', 'æœ‰æœºæº¶å‰‚', 'æ— æœºæº¶å‰‚', 'ç”²é†‡', 'ä¹™é†‡'])
    
    # åŒ…è£…ç‰©ç›¸å…³
    if any(word in name_lower for word in ['åŒ…è£…', 'å®¹å™¨', 'è¢‹', 'ç®±', 'æ¡¶']):
        keywords.extend(['åŒ…è£…', 'å®¹å™¨', 'è¢‹å­', 'çº¸ç®±', 'åŒ…è£…è¢‹', 'åŒ…è£…ç®±', 'æ¡¶'])
    
    # åŒ–éªŒç”¨å“ç›¸å…³
    if any(word in name_lower for word in ['åŒ–éªŒ', 'è¯•éªŒ', 'å®éªŒ', 'æ£€æµ‹']):
        keywords.extend(['åŒ–éªŒ', 'è¯•éªŒ', 'å®éªŒ', 'æ£€æµ‹', 'æµ‹è¯•', 'åˆ†æ', 'ä»ªå™¨'])
    
    # åŠ³ä¿ç”¨å“ç›¸å…³  
    if any(word in name_lower for word in ['åŠ³ä¿', 'é˜²æŠ¤', 'å®‰å…¨']):
        keywords.extend(['åŠ³ä¿', 'é˜²æŠ¤', 'å®‰å…¨', 'é˜²æŠ¤ç”¨å“', 'åŠ³ä¿ç”¨å“', 'å®‰å…¨ç”¨å“'])
    
    # æ¶ˆé˜²è®¾æ–½ç›¸å…³
    if any(word in name_lower for word in ['æ¶ˆé˜²', 'ç­ç«', 'æŠ¥è­¦']):
        keywords.extend(['æ¶ˆé˜²', 'ç­ç«', 'ç«ç¾', 'æŠ¥è­¦', 'æ¶ˆé˜²å™¨æ', 'ç­ç«å™¨'])
    
    # åŠå…¬ç”¨å“ç›¸å…³
    if any(word in name_lower for word in ['åŠå…¬', 'æ–‡å…·', 'çº¸å¼ ', 'ç¬”']):
        keywords.extend(['åŠå…¬', 'æ–‡å…·', 'åŠå…¬ç”¨å“', 'æ–‡å…·ç”¨å“', 'çº¸å¼ ', 'ç¬”'])
    
    # ç”µæ°”è®¾å¤‡ç›¸å…³
    if any(word in name_lower for word in ['ç”µæ°”', 'ç”µåŠ›', 'ç”µå­', 'ä»ªè¡¨', 'è‡ªæ§']):
        keywords.extend(['ç”µæ°”', 'ç”µåŠ›', 'ç”µå­', 'ä»ªè¡¨', 'è‡ªæ§', 'ç”µæ°”è®¾å¤‡', 'ç”µå­è®¾å¤‡'])
    
    # æœºæ¢°è®¾å¤‡ç›¸å…³
    if any(word in name_lower for word in ['æœºæ¢°', 'è®¾å¤‡', 'æ³µ', 'é˜€', 'ç®¡ä»¶']):
        keywords.extend(['æœºæ¢°', 'è®¾å¤‡', 'æ³µ', 'é˜€é—¨', 'ç®¡ä»¶', 'æœºæ¢°è®¾å¤‡', 'å·¥ä¸šè®¾å¤‡'])
    
    # å»ºç­‘ææ–™ç›¸å…³
    if any(word in name_lower for word in ['å»ºç­‘', 'é’¢æ', 'æ°´æ³¥', 'ç ‚çŸ³']):
        keywords.extend(['å»ºç­‘', 'å»ºæ', 'é’¢æ', 'æ°´æ³¥', 'ç ‚çŸ³', 'å»ºç­‘ææ–™'])
    
    # å·¥å…·ç›¸å…³
    if any(word in name_lower for word in ['å·¥å…·', 'åˆ€å…·', 'é‡å…·', 'å¤¹å…·']):
        keywords.extend(['å·¥å…·', 'åˆ€å…·', 'é‡å…·', 'å¤¹å…·', 'æ‰‹å·¥å·¥å…·', 'æµ‹é‡å·¥å…·'])
    
    # è¿è¾“è®¾å¤‡ç›¸å…³
    if any(word in name_lower for word in ['è¿è¾“', 'è½¦è¾†', 'å‰è½¦']):
        keywords.extend(['è¿è¾“', 'è½¦è¾†', 'å‰è½¦', 'è¿è¾“è®¾å¤‡', 'æ¬è¿è®¾å¤‡'])
    
    # é€šç”¨è®¾å¤‡ç›¸å…³
    if any(word in name_lower for word in ['é€šç”¨', 'è®¾å¤‡', 'å¤‡ä»¶']):
        keywords.extend(['é€šç”¨', 'è®¾å¤‡', 'å¤‡ä»¶', 'é€šç”¨è®¾å¤‡', 'æœºæ¢°å¤‡ä»¶'])
    
    # åˆå¹¶å¹¶å»é‡
    all_keywords = base_keywords + keywords
    return list(set(all_keywords))

def create_enhanced_classifier_config(keyword_mappings, categories_by_level):
    """åˆ›å»ºå¢å¼ºçš„åˆ†ç±»å™¨é…ç½®"""
    print("\\nâš™ï¸ åˆ›å»ºå¢å¼ºé…ç½®...")
    
    config = {
        'version': '2.0',
        'generated_time': '2025-09-28',
        'description': 'åŸºäºå®é™…548ä¸ªåˆ¶é€ ä¸šåˆ†ç±»çš„æ™ºèƒ½æ¨èé…ç½®',
        'statistics': {
            'total_categories': sum(len(cats) for cats in categories_by_level.values()),
            'level_distribution': {f'level_{k}': len(v) for k, v in categories_by_level.items()},
            'keyword_mappings_count': len(keyword_mappings)
        },
        'keyword_mappings': keyword_mappings,
        'categories_by_level': categories_by_level,
        'spec_patterns': {
            # æ”¹è¿›çš„è§„æ ¼æ¨¡å¼
            'chemical_purity': r'(\\d+(?:\\.\\d+)?)\\s*%',
            'diameter': r'[Ï†Î¦ç›´å¾„]\\s*(\\d+(?:\\.\\d+)?)\\s*mm',  
            'dimensions': r'(\\d+(?:\\.\\d+)?)\\s*[Ã—xX]\\s*(\\d+(?:\\.\\d+)?)',
            'voltage': r'(\\d+(?:\\.\\d+)?)\\s*[VvKkç”µå‹ä¼ç‰¹]',
            'power': r'(\\d+(?:\\.\\d+)?)\\s*[WwKkåŠŸç‡ç“¦ç‰¹åƒç“¦]',
            'capacity': r'(\\d+(?:\\.\\d+)?)\\s*[LlMmå®¹é‡å‡æ¯«å‡ç«‹æ–¹]',
            'weight': r'(\\d+(?:\\.\\d+)?)\\s*[KkGgåƒå…‹å…¬æ–¤å…‹å¨]',
            'chemical_formula': r'([A-Z][a-z]?[0-9]*)+',
            'model_number': r'[A-Z0-9\\-]{3,}',
            'temperature': r'(\\d+(?:\\.\\d+)?)\\s*[Â°â„ƒæ‘„æ°åº¦]'
        },
        'confidence_weights': {
            'exact_name_match': 0.95,
            'keyword_match': 0.7,
            'spec_pattern_match': 0.5,  
            'manufacturer_match': 0.6,
            'parent_category_match': 0.4
        }
    }
    
    # ä¿å­˜é…ç½®
    with open('enhanced_classifier_config.json', 'w', encoding='utf-8') as f:
        json.dump(config, f, ensure_ascii=False, indent=2)
    
    print("âœ… å¢å¼ºé…ç½®å·²ä¿å­˜åˆ° enhanced_classifier_config.json")
    return config

def create_improved_classifier_patch():
    """åˆ›å»ºæ”¹è¿›çš„åˆ†ç±»å™¨è¡¥ä¸ä»£ç """
    print("\\nğŸ”§ åˆ›å»ºåˆ†ç±»å™¨æ”¹è¿›è¡¥ä¸...")
    
    patch_code = '''#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ™ºèƒ½åˆ†ç±»å™¨å¢å¼ºè¡¥ä¸
åº”ç”¨åŸºäºå®é™…æ•°æ®åº“çš„æ”¹è¿›ç®—æ³•
"""

import json
import os
from typing import Dict, List, Any

class EnhancedClassifierPatch:
    """å¢å¼ºåˆ†ç±»å™¨è¡¥ä¸"""
    
    def __init__(self, config_file='enhanced_classifier_config.json'):
        self.config = self.load_config(config_file)
        
    def load_config(self, config_file: str) -> Dict:
        """åŠ è½½å¢å¼ºé…ç½®"""
        if os.path.exists(config_file):
            with open(config_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        return {}
    
    def enhanced_keyword_matching(self, text: str, categories: List[Dict]) -> List[Dict]:
        """å¢å¼ºçš„å…³é”®è¯åŒ¹é…"""
        recommendations = []
        text_lower = text.lower()
        
        keyword_mappings = self.config.get('keyword_mappings', {})
        confidence_weights = self.config.get('confidence_weights', {})
        
        for category_name, keywords in keyword_mappings.items():
            # å¯»æ‰¾åŒ¹é…çš„å®é™…åˆ†ç±»
            matching_category = None
            for cat in categories:
                if cat.get('category_name') == category_name or cat.get('name') == category_name:
                    matching_category = cat
                    break
            
            if not matching_category:
                continue
                
            confidence = 0.0
            matched_keywords = []
            
            # ç²¾ç¡®åç§°åŒ¹é…
            if category_name.lower() in text_lower:
                confidence += confidence_weights.get('exact_name_match', 0.95)
                matched_keywords.append(f"ç²¾ç¡®åŒ¹é…:{category_name}")
            
            # å…³é”®è¯åŒ¹é…
            for keyword in keywords:
                if keyword.lower() in text_lower:
                    confidence += confidence_weights.get('keyword_match', 0.7) / len(keywords)
                    matched_keywords.append(keyword)
            
            if confidence > 0.1:  # ç½®ä¿¡åº¦é˜ˆå€¼
                recommendations.append({
                    'category_id': matching_category.get('id'),
                    'category_name': category_name,
                    'confidence': min(confidence, 1.0),
                    'reason': f"å…³é”®è¯åŒ¹é…: {', '.join(matched_keywords[:3])}",
                    'source': 'enhanced_keyword_matching',
                    'matched_keywords': matched_keywords
                })
        
        return sorted(recommendations, key=lambda x: x['confidence'], reverse=True)
    
    def smart_fallback_recommendation(self, text: str, categories: List[Dict]) -> List[Dict]:
        """æ™ºèƒ½å¤‡ç”¨æ¨è"""
        recommendations = []
        text_lower = text.lower()
        
        # åŸºäºä¸€çº§åˆ†ç±»çš„æ¨¡ç³ŠåŒ¹é…
        level1_categories = [cat for cat in categories if cat.get('level') == 1]
        
        for category in level1_categories[:5]:  # åªè€ƒè™‘å‰5ä¸ªä¸€çº§åˆ†ç±»
            category_name = category.get('category_name', '')
            
            # ç®€å•çš„å­—ç¬¦åŒ¹é…
            common_chars = set(text_lower) & set(category_name.lower())
            if len(common_chars) >= 2:  # è‡³å°‘2ä¸ªå…±åŒå­—ç¬¦
                recommendations.append({
                    'category_id': category.get('id'),
                    'category_name': category_name,
                    'confidence': len(common_chars) / max(len(text_lower), len(category_name)),
                    'reason': f"æ¨¡ç³ŠåŒ¹é…: å…±åŒå­—ç¬¦ {len(common_chars)} ä¸ª",
                    'source': 'smart_fallback'
                })
        
        return sorted(recommendations, key=lambda x: x['confidence'], reverse=True)[:3]

def apply_enhanced_classifier_patch():
    """åº”ç”¨å¢å¼ºåˆ†ç±»å™¨è¡¥ä¸"""
    print("åº”ç”¨åˆ†ç±»å™¨å¢å¼ºè¡¥ä¸...")
    
    # è¿™é‡Œå¯ä»¥æ·»åŠ åŠ¨æ€è¡¥ä¸ä»£ç 
    # æˆ–è€…ç”Ÿæˆæ–°çš„åˆ†ç±»å™¨å®ç°
    
    return True

if __name__ == "__main__":
    patch = EnhancedClassifierPatch()
    apply_enhanced_classifier_patch()
'''
    
    with open('enhanced_classifier_patch.py', 'w', encoding='utf-8') as f:
        f.write(patch_code)
    
    print("âœ… åˆ†ç±»å™¨æ”¹è¿›è¡¥ä¸å·²ä¿å­˜åˆ° enhanced_classifier_patch.py")
    return True

def test_enhanced_mappings(keyword_mappings, categories_by_level):
    """æµ‹è¯•å¢å¼ºçš„æ˜ å°„æ•ˆæœ"""
    print("\\nğŸ§ª æµ‹è¯•å¢å¼ºæ˜ å°„...")
    
    test_cases = [
        "å‚¬åŒ–å‰‚è½½ä½“",
        "åŒ–å·¥åŠ©å‰‚", 
        "åŒ…è£…è¢‹",
        "åŒ–éªŒä»ªå™¨",
        "é˜²æŠ¤ç”¨å“",
        "æ¶ˆé˜²å™¨æ",
        "åŠå…¬çº¸å¼ ",
        "ç”µæ°”è®¾å¤‡",
        "æœºæ¢°æ³µ",
        "å»ºç­‘é’¢æ"
    ]
    
    print("æµ‹è¯•ç»“æœ:")
    for test_text in test_cases:
        matched_categories = []
        
        for category_name, keywords in keyword_mappings.items():
            if any(keyword.lower() in test_text.lower() for keyword in keywords):
                matched_categories.append(category_name)
        
        print(f"  '{test_text}' -> åŒ¹é…åˆ†ç±»: {matched_categories[:3]}")
    
    return True

def main():
    """ä¸»å‡½æ•°"""
    print("=" * 60)
    print("     åŸºäºå®é™…æ•°æ®åº“çš„æ™ºèƒ½åˆ†ç±»æ˜ å°„ä¼˜åŒ–")
    print("=" * 60)
    
    # 1. åˆ†æç°æœ‰åˆ†ç±»æ•°æ®
    categories_by_level = analyze_existing_categories()
    
    if not categories_by_level:
        print("âŒ æ— æ³•è·å–åˆ†ç±»æ•°æ®ï¼Œé€€å‡º")
        return
    
    # 2. æ„å»ºæ™ºèƒ½å…³é”®è¯æ˜ å°„
    keyword_mappings = build_smart_keyword_mappings(categories_by_level)
    
    # 3. åˆ›å»ºå¢å¼ºé…ç½®
    config = create_enhanced_classifier_config(keyword_mappings, categories_by_level)
    
    # 4. åˆ›å»ºæ”¹è¿›è¡¥ä¸
    create_improved_classifier_patch()
    
    # 5. æµ‹è¯•æ˜ å°„æ•ˆæœ
    test_enhanced_mappings(keyword_mappings, categories_by_level)
    
    print("\\n" + "=" * 60)
    print("âœ… æ™ºèƒ½åˆ†ç±»æ˜ å°„ä¼˜åŒ–å®Œæˆï¼")
    print("   - ç”Ÿæˆäº†åŸºäºå®é™…548ä¸ªåˆ†ç±»çš„å…³é”®è¯æ˜ å°„")
    print("   - åˆ›å»ºäº†å¢å¼ºé…ç½®æ–‡ä»¶")
    print("   - æä¾›äº†æ”¹è¿›è¡¥ä¸ä»£ç ")
    print("   å»ºè®®æ¥ä¸‹æ¥å°†è¿™äº›æ”¹è¿›é›†æˆåˆ°ä¸»åˆ†ç±»å™¨ä¸­ã€‚")

if __name__ == "__main__":
    main()