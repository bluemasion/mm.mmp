# MMPæ™ºèƒ½åˆ†ç±»å¢å¼ºå­¦ä¹ æ‰©å±•è®¾è®¡æ–¹æ¡ˆ

## ğŸ“Š å½“å‰ç³»ç»ŸçŠ¶æ€åˆ†æ (2025å¹´9æœˆ22æ—¥)

### ç°æœ‰æ™ºèƒ½åˆ†ç±»ç®—æ³•è¡¨ç°
- **æ¨èè¦†ç›–ç‡**: 80% (4/5ç‰©æ–™æœ‰æ¨è)
- **ç½®ä¿¡åº¦åˆ†å¸ƒ**: 
  - ğŸ”´ ä½ç½®ä¿¡åº¦(<50%): 87.5%
  - ğŸŸ¡ ä¸­ç½®ä¿¡åº¦(50-70%): 12.5% 
  - ğŸŸ¢ é«˜ç½®ä¿¡åº¦(â‰¥70%): 0%
- **ç®—æ³•ä½¿ç”¨åˆ†å¸ƒ**:
  - keyword_matching: 4æ¬¡
  - spec_pattern: 3æ¬¡
  - ç»„åˆç®—æ³•: 1æ¬¡

### ä¸»è¦é—®é¢˜è¯Šæ–­
1. **å…³é”®è¯è¯å…¸è¦†ç›–ä¸è¶³**: "åŒ»ç”¨é˜²æŠ¤å£ç½©"æ— æ³•è¯†åˆ«
2. **è§„æ ¼æ¨¡å¼åŒ¹é…è¿‡äºç®€å•**: ä»…åŸºç¡€æ­£åˆ™è¡¨è¾¾å¼
3. **åˆ†ç±»ä½“ç³»ä¸å®Œæ•´**: å¤§é‡ä¸´æ—¶åˆ†ç±»åˆ›å»º
4. **è¯­ä¹‰ç†è§£èƒ½åŠ›ç¼ºå¤±**: æ— æ³•å¤„ç†å¤æ‚æè¿°

## ğŸ¯ ç½®ä¿¡åº¦æå‡é¢„ä¼°

### çŸ­æœŸä¼˜åŒ–é¢„æœŸæ•ˆæœ
```
å½“å‰çŠ¶æ€ â†’ è§„åˆ™å¢å¼ºåé¢„æœŸ
â”œâ”€â”€ æ¨èè¦†ç›–ç‡: 80% â†’ 95%
â”œâ”€â”€ é«˜ç½®ä¿¡åº¦(â‰¥70%): 0% â†’ 25-35%  
â”œâ”€â”€ ä¸­ç½®ä¿¡åº¦(50-70%): 12.5% â†’ 40-50%
â””â”€â”€ ä½ç½®ä¿¡åº¦(<50%): 87.5% â†’ 15-25%
```

### å…·ä½“æå‡ç­–ç•¥åŠé¢„æœŸæ”¶ç›Š
1. **æ‰©å……å…³é”®è¯è¯å…¸**: ç½®ä¿¡åº¦+15-20%
2. **ä¼˜åŒ–è§„æ ¼æ¨¡å¼è¯†åˆ«**: ç½®ä¿¡åº¦+10-15% 
3. **å®Œå–„åˆ†ç±»ä½“ç³»**: ç½®ä¿¡åº¦+10-15%
4. **å¼•å…¥åˆ¶é€ å•†æƒé‡**: ç½®ä¿¡åº¦+5-10%
5. **æ·»åŠ è¯­ä¹‰ç›¸ä¼¼åº¦**: ç½®ä¿¡åº¦+20-30%

## ğŸ—ï¸ å¢å¼ºå­¦ä¹ ç³»ç»Ÿæ¶æ„è®¾è®¡

### ç³»ç»Ÿåˆ†å±‚æ¶æ„
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 ç”¨æˆ·ç•Œé¢å±‚                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  å‚æ•°æå–é¡µé¢  â”‚  åé¦ˆæ”¶é›†ç•Œé¢  â”‚  ç®¡ç†åå°     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 ä¸šåŠ¡é€»è¾‘å±‚                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ æ™ºèƒ½æ¨èæœåŠ¡ â”‚ åé¦ˆå¤„ç†æœåŠ¡ â”‚ å­¦ä¹ è®­ç»ƒæœåŠ¡     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 ç®—æ³•æ¨¡å‹å±‚                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ è§„åˆ™å¼•æ“ â”‚ æœºå™¨å­¦ä¹ æ¨¡å‹ â”‚ å¼ºåŒ–å­¦ä¹ æ¨¡å—        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 æ•°æ®å­˜å‚¨å±‚                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ä¸šåŠ¡æ•°æ® â”‚ åé¦ˆæ•°æ® â”‚ è®­ç»ƒæ•°æ® â”‚ æ¨¡å‹ç‰ˆæœ¬      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“Š æ•°æ®åº“æ‰©å±•è®¾è®¡

### æ–°å¢è¡¨ç»“æ„

#### 1. ç”¨æˆ·åé¦ˆè¡¨
```sql
CREATE TABLE user_feedback (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    session_id TEXT NOT NULL,
    material_name TEXT NOT NULL,
    material_spec TEXT,
    manufacturer TEXT,
    recommended_category TEXT,
    user_selected_category TEXT,
    feedback_type TEXT, -- 'accept', 'reject', 'modify'
    confidence_score REAL,
    algorithm_source TEXT,
    feedback_time TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    user_comment TEXT,
    FOREIGN KEY (session_id) REFERENCES session_data(session_id)
);

-- ç´¢å¼•ä¼˜åŒ–
CREATE INDEX idx_feedback_session ON user_feedback(session_id);
CREATE INDEX idx_feedback_time ON user_feedback(feedback_time);
CREATE INDEX idx_feedback_material ON user_feedback(material_name);
```

#### 2. å­¦ä¹ æ ·æœ¬è¡¨
```sql
CREATE TABLE training_samples (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    material_features TEXT, -- JSONæ ¼å¼å­˜å‚¨ç‰¹å¾
    true_category TEXT,
    sample_weight REAL DEFAULT 1.0,
    data_source TEXT, -- 'feedback', 'manual', 'import'
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    is_validated BOOLEAN DEFAULT 0,
    feature_hash TEXT, -- ç‰¹å¾å“ˆå¸Œé¿å…é‡å¤
    UNIQUE(feature_hash)
);

-- ç´¢å¼•ä¼˜åŒ–
CREATE INDEX idx_samples_category ON training_samples(true_category);
CREATE INDEX idx_samples_source ON training_samples(data_source);
CREATE INDEX idx_samples_validated ON training_samples(is_validated);
```

#### 3. æ¨¡å‹ç‰ˆæœ¬ç®¡ç†è¡¨
```sql
CREATE TABLE model_versions (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    version_name TEXT UNIQUE,
    model_type TEXT, -- 'rule_based', 'ml_model', 'hybrid'
    model_path TEXT,
    performance_metrics TEXT, -- JSONæ ¼å¼å­˜å‚¨æŒ‡æ ‡
    is_active BOOLEAN DEFAULT 0,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    deployment_time TIMESTAMP,
    rollback_version TEXT
);

-- ç¡®ä¿åªæœ‰ä¸€ä¸ªæ´»è·ƒç‰ˆæœ¬
CREATE UNIQUE INDEX idx_active_model ON model_versions(is_active) 
WHERE is_active = 1;
```

#### 4. ç®—æ³•æ€§èƒ½ç›‘æ§è¡¨
```sql
CREATE TABLE algorithm_metrics (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    date DATE,
    hour INTEGER, -- 0-23 å°æ—¶çº§ç›‘æ§
    total_requests INTEGER,
    successful_predictions INTEGER,
    avg_confidence REAL,
    user_acceptance_rate REAL,
    model_version TEXT,
    algorithm_breakdown TEXT, -- JSONæ ¼å¼å­˜å‚¨å„ç®—æ³•ä½¿ç”¨æƒ…å†µ
    PRIMARY KEY (date, hour, model_version)
);

-- ç´¢å¼•ä¼˜åŒ–
CREATE INDEX idx_metrics_date ON algorithm_metrics(date);
CREATE INDEX idx_metrics_version ON algorithm_metrics(model_version);
```

## ğŸ”„ APIæ¥å£æ‰©å±•è®¾è®¡

### 1. åé¦ˆæ”¶é›†æ¥å£
```python
@app.route('/api/feedback/submit', methods=['POST'])
def submit_feedback():
    """
    æäº¤ç”¨æˆ·åé¦ˆ
    
    Request Body:
    {
        "session_id": "xxx-xxx-xxx",
        "material_info": {
            "name": "ä¸€æ¬¡æ€§æ³¨å°„å™¨",
            "spec": "5ml", 
            "manufacturer": "å¨é«˜é›†å›¢"
        },
        "recommendations": [
            {
                "category": "åŒ»ç–—å™¨æ¢°",
                "confidence": 0.45,
                "source": "keyword_matching"
            }
        ],
        "user_feedback": {
            "selected_category": "æ³¨å°„å™¨å…·",
            "feedback_type": "modify", 
            "confidence_rating": 8,
            "comment": "æ¨èåŸºæœ¬å‡†ç¡®ä½†åˆ†ç±»è¿‡äºå®½æ³›"
        }
    }
    
    Response:
    {
        "success": true,
        "message": "åé¦ˆå·²æ”¶å½•ï¼Œæ„Ÿè°¢æ‚¨çš„è´¡çŒ®",
        "feedback_id": 12345,
        "learning_triggered": false
    }
    """
```

### 2. å­¦ä¹ è®­ç»ƒæ¥å£
```python
@app.route('/api/learning/trigger_training', methods=['POST'])
def trigger_training():
    """
    è§¦å‘æ¨¡å‹è®­ç»ƒ
    
    Request Body:
    {
        "training_mode": "incremental", // or "full_retrain"
        "min_samples": 50,
        "validation_split": 0.2,
        "algorithm_types": ["ml_model", "rule_enhancement"]
    }
    
    Response:
    {
        "success": true,
        "training_id": "train_20250922_001",
        "estimated_duration": "15 minutes",
        "status": "queued"
    }
    """
```

### 3. æ¨¡å‹æ€§èƒ½ç›‘æ§æ¥å£
```python
@app.route('/api/admin/model_performance', methods=['GET'])
def get_model_performance():
    """
    è·å–æ¨¡å‹æ€§èƒ½æŒ‡æ ‡
    
    Query Parameters:
    - date_range: "7d", "30d", "90d"
    - model_version: "v1.2.3"
    
    Response:
    {
        "success": true,
        "metrics": {
            "accuracy": 0.78,
            "precision": 0.82, 
            "recall": 0.75,
            "f1_score": 0.78,
            "user_satisfaction": 0.85
        },
        "trends": [...],
        "algorithm_breakdown": {...}
    }
    """
```

## ğŸ¤– å¢å¼ºå­¦ä¹ ç®—æ³•è®¾è®¡

### MMPå…¨ç³»ç»Ÿç®—æ³•æ¶æ„å›¾

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      MMPæ™ºèƒ½ç®—æ³•ç”Ÿæ€ç³»ç»Ÿ                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  ğŸ§  æ™ºèƒ½åˆ†ç±»æ¨è  â”‚  ğŸ” æ™ºèƒ½åŒ¹é…ç®—æ³•  â”‚  ğŸ“Š å‚æ•°æå–ä¼˜åŒ–     â”‚
â”‚     â†“                  â†“                 â†“              â”‚
â”‚ â€¢ å…³é”®è¯åŒ¹é…      â”‚ â€¢ ç›¸ä¼¼åº¦è®¡ç®—      â”‚ â€¢ å­—æ®µè¯†åˆ«        â”‚
â”‚ â€¢ è§„æ ¼æ¨¡å¼è¯†åˆ«    â”‚ â€¢ æ¨¡ç³ŠåŒ¹é…       â”‚ â€¢ æ•°æ®æ¸…æ´—        â”‚
â”‚ â€¢ è¯­ä¹‰ç›¸ä¼¼åº¦      â”‚ â€¢ å†å²è®°å½•æƒé‡    â”‚ â€¢ å¼‚å¸¸æ£€æµ‹        â”‚
â”‚ â€¢ åˆ¶é€ å•†åˆ†æ      â”‚ â€¢ ç”¨æˆ·åå¥½å­¦ä¹     â”‚ â€¢ è´¨é‡è¯„åˆ†        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   ğŸ¤– ç»Ÿä¸€å¢å¼ºå­¦ä¹ æ¡†æ¶                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  å¼ºåŒ–å­¦ä¹ æ™ºèƒ½ä½“ (RL Agent) - è·¨æ¨¡å—åè°ƒä¼˜åŒ–                   â”‚
â”‚  â€¢ å…¨å±€å¥–åŠ±å‡½æ•°è®¾è®¡                                         â”‚
â”‚  â€¢ å¤šç›®æ ‡ä¼˜åŒ– (å‡†ç¡®æ€§ + æ•ˆç‡ + ç”¨æˆ·æ»¡æ„åº¦)                   â”‚
â”‚  â€¢ è‡ªé€‚åº”æƒé‡è°ƒæ•´                                           â”‚
â”‚  â€¢ åœ¨çº¿å­¦ä¹ å’Œæ¨¡å‹æ›´æ–°                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### å¤šå±‚æ¬¡å­¦ä¹ æ¶æ„

```python
class EnhancedLearningSystem:
    """MMPå…¨ç³»ç»Ÿå¢å¼ºå­¦ä¹ æ ¸å¿ƒç±»"""
    
    def __init__(self, config_manager, db_manager):
        self.config = config_manager
        self.db = db_manager
        
        # === å¤šç®—æ³•æ¨¡å—ç»„ä»¶ ===
        self.classification_engine = ClassificationEngine(config_manager)
        self.matching_engine = IntelligentMatchingEngine(config_manager) 
        self.extraction_engine = ParameterExtractionEngine(config_manager)
        
        # === å¢å¼ºå­¦ä¹ ç»„ä»¶ ===
        self.rl_coordinator = RLCoordinator(config_manager)
        self.feedback_processor = FeedbackProcessor(db_manager)
        self.model_optimizer = ModelOptimizer(config_manager)
        
        # === åŠ¨æ€æƒé‡å’Œç­–ç•¥ ===
        self.algorithm_weights = {
            'classification': {'rule': 0.4, 'ml': 0.4, 'rl': 0.2},
            'matching': {'similarity': 0.5, 'history': 0.3, 'rl': 0.2},
            'extraction': {'rule': 0.6, 'ml': 0.2, 'rl': 0.2}
        }
        
    def predict_with_feedback_loop(self, material_features, session_id=None):
        """å¸¦åé¦ˆå¾ªç¯çš„æ™ºèƒ½é¢„æµ‹"""
        
        # 1. å¤šæ¨¡å‹å¹¶è¡Œé¢„æµ‹
        rule_predictions = self.rule_engine.predict(material_features)
        ml_predictions = self.ml_model.predict(material_features) 
        
        # 2. é›†æˆé¢„æµ‹ç»“æœ
        ensemble_predictions = self._ensemble_predictions(
            rule_predictions, 
            ml_predictions,
            material_features
        )
        
        # 3. å¼ºåŒ–å­¦ä¹ åŠ¨æ€è°ƒæ•´
        if session_id and self._has_historical_feedback(session_id):
            adjusted_predictions = self.rl_agent.adjust_predictions(
                ensemble_predictions,
                material_features,
                session_id
            )
        else:
            adjusted_predictions = ensemble_predictions
            
        # 4. è®°å½•é¢„æµ‹æ—¥å¿—
        self._log_prediction(material_features, adjusted_predictions)
        
        return adjusted_predictions
    
    def unified_intelligent_processing(self, materials_data, session_id):
        """ç»Ÿä¸€æ™ºèƒ½å¤„ç†æµç¨‹ - æ•´åˆåˆ†ç±»ã€åŒ¹é…ã€æå–ä¸‰å¤§æ¨¡å—"""
        
        results = []
        for material in materials_data:
            # 1. å‚æ•°æå–ä¸ä¼˜åŒ–
            extracted_params = self.extraction_engine.extract_and_optimize(
                material, session_id
            )
            
            # 2. æ™ºèƒ½åˆ†ç±»æ¨è
            classification_results = self.classification_engine.classify_with_rl(
                extracted_params, session_id
            )
            
            # 3. æ™ºèƒ½åŒ¹é…åˆ†æ
            matching_results = self.matching_engine.find_matches_with_rl(
                extracted_params, session_id
            )
            
            # 4. å…¨å±€å¼ºåŒ–å­¦ä¹ ä¼˜åŒ–
            optimized_results = self.rl_coordinator.optimize_results(
                classification_results, 
                matching_results, 
                extracted_params,
                session_id
            )
            
            results.append({
                'material_info': material,
                'extracted_params': extracted_params,
                'classifications': classification_results,
                'matches': matching_results,
                'recommendations': optimized_results
            })
            
        return results
        
    def _ensemble_predictions(self, rule_preds, ml_preds, features):
        """æ™ºèƒ½é›†æˆå¤šæ¨¡å‹é¢„æµ‹ç»“æœ"""
        
        # åŸºäºç‰¹å¾å¤æ‚åº¦åŠ¨æ€è°ƒæ•´æƒé‡
        complexity_score = self._calculate_complexity(features)
        
        if complexity_score > 0.7:  # å¤æ‚ç‰¹å¾ï¼Œæ›´ä¾èµ–MLæ¨¡å‹
            weights = {'rule': 0.3, 'ml': 0.7}
        else:  # ç®€å•ç‰¹å¾ï¼Œè§„åˆ™å¼•æ“æ›´å¯é 
            weights = {'rule': 0.6, 'ml': 0.4}
            
        # åŠ æƒèåˆé¢„æµ‹ç»“æœ
        ensemble_results = []
        for rule_pred, ml_pred in zip(rule_preds, ml_preds):
            ensemble_confidence = (
                rule_pred['confidence'] * weights['rule'] + 
                ml_pred['confidence'] * weights['ml']
            )
            
            # é€‰æ‹©ç½®ä¿¡åº¦æ›´é«˜çš„åˆ†ç±»ï¼Œä½†è°ƒæ•´ç½®ä¿¡åº¦
            if rule_pred['confidence'] > ml_pred['confidence']:
                result = rule_pred.copy()
                result['confidence'] = ensemble_confidence
                result['source'] = f"ensemble({rule_pred['source']}+{ml_pred['source']})"
            else:
                result = ml_pred.copy() 
                result['confidence'] = ensemble_confidence
                result['source'] = f"ensemble({ml_pred['source']}+{rule_pred['source']})"
                
            ensemble_results.append(result)
            
        return ensemble_results
```

### åé¦ˆå¤„ç†æµç¨‹

```python
class FeedbackProcessor:
    """ç”¨æˆ·åé¦ˆå¤„ç†å™¨"""
    
    def __init__(self, db_manager, learning_system):
        self.db = db_manager
        self.learning_system = learning_system
        self.feedback_threshold = 50  # è§¦å‘å­¦ä¹ çš„åé¦ˆæ•°é‡é˜ˆå€¼
        
    def process_user_feedback(self, feedback_data):
        """å¤„ç†ç”¨æˆ·åé¦ˆçš„å®Œæ•´æµç¨‹"""
        
        # 1. éªŒè¯å’Œæ¸…ç†åé¦ˆæ•°æ®
        cleaned_feedback = self._validate_feedback(feedback_data)
        
        # 2. å­˜å‚¨åé¦ˆåˆ°æ•°æ®åº“
        feedback_id = self._store_feedback(cleaned_feedback)
        
        # 3. å³æ—¶è§„åˆ™æ›´æ–°ï¼ˆè½»é‡çº§ï¼‰
        self._update_rules_immediately(cleaned_feedback)
        
        # 4. æ›´æ–°æ ·æœ¬æƒé‡
        self._update_sample_weights(cleaned_feedback)
        
        # 5. æ£€æŸ¥æ˜¯å¦è§¦å‘æ‰¹é‡å­¦ä¹ 
        learning_triggered = False
        if self._should_trigger_batch_learning():
            self._queue_batch_learning()
            learning_triggered = True
            
        # 6. æ›´æ–°å®æ—¶ç»Ÿè®¡
        self._update_realtime_metrics(cleaned_feedback)
        
        return {
            'feedback_id': feedback_id,
            'learning_triggered': learning_triggered,
            'status': 'processed'
        }

### æ™ºèƒ½åŒ¹é…ç®—æ³•å¢å¼ºå­¦ä¹ è®¾è®¡

```python
class IntelligentMatchingEngine:
    """æ™ºèƒ½åŒ¹é…å¼•æ“ - é›†æˆå¢å¼ºå­¦ä¹ """
    
    def __init__(self, config_manager):
        self.config = config_manager
        
        # ä¼ ç»ŸåŒ¹é…ç®—æ³•
        self.similarity_matcher = SimilarityMatcher()
        self.fuzzy_matcher = FuzzyMatcher() 
        self.history_matcher = HistoryBasedMatcher()
        
        # å¢å¼ºå­¦ä¹ ç»„ä»¶
        self.matching_rl_agent = MatchingRLAgent()
        self.user_preference_learner = UserPreferenceLearner()
        
        # åŠ¨æ€æƒé‡
        self.matching_weights = {
            'exact_match': 1.0,      # å®Œå…¨åŒ¹é…æƒé‡æœ€é«˜
            'similarity': 0.8,       # ç›¸ä¼¼åº¦åŒ¹é…
            'fuzzy': 0.6,           # æ¨¡ç³ŠåŒ¹é… 
            'history': 0.7,         # å†å²è®°å½•åŒ¹é…
            'user_preference': 0.5   # ç”¨æˆ·åå¥½åŒ¹é…
        }
        
    def find_matches_with_rl(self, material_features, session_id):
        """åŸºäºå¼ºåŒ–å­¦ä¹ çš„æ™ºèƒ½åŒ¹é…"""
        
        # 1. å¤šç­–ç•¥åŒ¹é…
        exact_matches = self._exact_match(material_features)
        similarity_matches = self.similarity_matcher.find_matches(material_features)
        fuzzy_matches = self.fuzzy_matcher.find_matches(material_features)
        history_matches = self.history_matcher.find_matches(material_features, session_id)
        
        # 2. ç”¨æˆ·åå¥½å­¦ä¹ 
        user_preferences = self.user_preference_learner.get_preferences(session_id)
        preference_matches = self._apply_user_preferences(
            similarity_matches, user_preferences
        )
        
        # 3. å¼ºåŒ–å­¦ä¹ ä¼˜åŒ–åŒ¹é…ç»“æœ
        all_matches = {
            'exact': exact_matches,
            'similarity': similarity_matches, 
            'fuzzy': fuzzy_matches,
            'history': history_matches,
            'preference': preference_matches
        }
        
        # 4. RLæ™ºèƒ½ä½“å†³ç­–æœ€ä¼˜åŒ¹é…ç»„åˆ
        optimized_matches = self.matching_rl_agent.optimize_matches(
            all_matches, 
            material_features,
            session_id
        )
        
        return optimized_matches
        
    def learn_from_matching_feedback(self, feedback_data):
        """ä»åŒ¹é…åé¦ˆä¸­å­¦ä¹ """
        
        # æ›´æ–°ç›¸ä¼¼åº¦è®¡ç®—æƒé‡
        self.similarity_matcher.update_weights(feedback_data)
        
        # æ›´æ–°ç”¨æˆ·åå¥½æ¨¡å‹
        self.user_preference_learner.update_preferences(feedback_data)
        
        # è®­ç»ƒå¼ºåŒ–å­¦ä¹ æ™ºèƒ½ä½“
        reward = self._calculate_matching_reward(feedback_data)
        self.matching_rl_agent.update_policy(feedback_data, reward)

class MatchingRLAgent:
    """åŒ¹é…ä¸“ç”¨å¼ºåŒ–å­¦ä¹ æ™ºèƒ½ä½“"""
    
    def __init__(self):
        self.q_table = {}  # Q-learningè¡¨
        self.epsilon = 0.1  # æ¢ç´¢ç‡
        self.alpha = 0.1    # å­¦ä¹ ç‡
        self.gamma = 0.9    # æŠ˜æ‰£å› å­
        
        # çŠ¶æ€ç‰¹å¾
        self.state_features = [
            'material_name_similarity',
            'spec_similarity', 
            'manufacturer_similarity',
            'category_match',
            'historical_preference',
            'user_behavior_pattern'
        ]
        
    def optimize_matches(self, all_matches, material_features, session_id):
        """ä¼˜åŒ–åŒ¹é…ç»“æœæ’åºå’Œæƒé‡"""
        
        # 1. æ„å»ºå½“å‰çŠ¶æ€
        current_state = self._build_state(material_features, session_id)
        
        # 2. é€‰æ‹©åŠ¨ä½œ(åŒ¹é…ç­–ç•¥ç»„åˆ)
        action = self._select_action(current_state)
        
        # 3. åº”ç”¨åŠ¨ä½œä¼˜åŒ–åŒ¹é…ç»“æœ
        optimized_results = self._apply_matching_action(
            all_matches, action, material_features
        )
        
        # 4. è®°å½•çŠ¶æ€-åŠ¨ä½œå¯¹ï¼Œç­‰å¾…åé¦ˆ
        self._record_state_action(current_state, action, session_id)
        
        return optimized_results
        
    def _calculate_matching_reward(self, feedback_data):
        """è®¡ç®—åŒ¹é…å¥–åŠ±å‡½æ•°"""
        
        base_reward = 0
        
        # åŒ¹é…å‡†ç¡®æ€§å¥–åŠ±
        if feedback_data.get('match_accepted'):
            base_reward += 2.0
        elif feedback_data.get('match_rejected'):
            base_reward -= 1.0
            
        # åŒ¹é…é€Ÿåº¦å¥–åŠ±(ç”¨æˆ·ç‚¹å‡»åŒ¹é…é¡¹çš„ä½ç½®)
        click_position = feedback_data.get('click_position', 10)
        position_reward = max(0, (10 - click_position) * 0.1)
        
        # ç”¨æˆ·æ»¡æ„åº¦å¥–åŠ±
        satisfaction = feedback_data.get('satisfaction_rating', 5)
        satisfaction_reward = (satisfaction - 5) * 0.2
        
        return base_reward + position_reward + satisfaction_reward

class UserPreferenceLearner:
    """ç”¨æˆ·åå¥½å­¦ä¹ æ¨¡å—"""
    
    def __init__(self):
        self.preference_profiles = {}  # ç”¨æˆ·åå¥½æ¡£æ¡ˆ
        
    def get_preferences(self, session_id):
        """è·å–ç”¨æˆ·åå¥½"""
        return self.preference_profiles.get(session_id, {
            'preferred_manufacturers': {},
            'preferred_categories': {},
            'matching_behavior': {
                'prefers_exact_match': 0.5,
                'tolerates_fuzzy_match': 0.3,
                'values_historical_data': 0.4
            }
        })
        
    def update_preferences(self, feedback_data):
        """æ›´æ–°ç”¨æˆ·åå¥½æ¨¡å‹"""
        
        session_id = feedback_data.get('session_id')
        if not session_id:
            return
            
        if session_id not in self.preference_profiles:
            self.preference_profiles[session_id] = self._init_preference_profile()
            
        profile = self.preference_profiles[session_id]
        
        # æ›´æ–°åˆ¶é€ å•†åå¥½
        manufacturer = feedback_data.get('manufacturer')
        if manufacturer and feedback_data.get('match_accepted'):
            profile['preferred_manufacturers'][manufacturer] = \
                profile['preferred_manufacturers'].get(manufacturer, 0) + 0.1
                
        # æ›´æ–°åˆ†ç±»åå¥½
        category = feedback_data.get('selected_category') 
        if category:
            profile['preferred_categories'][category] = \
                profile['preferred_categories'].get(category, 0) + 0.1
                
        # æ›´æ–°åŒ¹é…è¡Œä¸ºåå¥½
        match_type = feedback_data.get('match_type')
        if match_type and feedback_data.get('match_accepted'):
            if match_type == 'exact':
                profile['matching_behavior']['prefers_exact_match'] += 0.05
            elif match_type == 'fuzzy':
                profile['matching_behavior']['tolerates_fuzzy_match'] += 0.05
```

### å‚æ•°æå–ç®—æ³•å¢å¼ºå­¦ä¹ è®¾è®¡

```python
class ParameterExtractionEngine:
    """å‚æ•°æå–å¼•æ“ - é›†æˆå¢å¼ºå­¦ä¹ """
    
    def __init__(self, config_manager):
        self.config = config_manager
        
        # ä¼ ç»Ÿæå–ç®—æ³•
        self.rule_extractor = RuleBasedExtractor()
        self.ml_extractor = MLBasedExtractor()
        self.pattern_extractor = PatternExtractor()
        
        # å¢å¼ºå­¦ä¹ ç»„ä»¶  
        self.extraction_rl_agent = ExtractionRLAgent()
        self.field_quality_assessor = FieldQualityAssessor()
        
    def extract_and_optimize(self, material_data, session_id):
        """æ™ºèƒ½å‚æ•°æå–ä¸ä¼˜åŒ–"""
        
        # 1. å¤šç­–ç•¥æå–
        rule_results = self.rule_extractor.extract(material_data)
        ml_results = self.ml_extractor.extract(material_data) 
        pattern_results = self.pattern_extractor.extract(material_data)
        
        # 2. è´¨é‡è¯„ä¼°
        quality_scores = self.field_quality_assessor.assess_quality([
            rule_results, ml_results, pattern_results
        ])
        
        # 3. å¼ºåŒ–å­¦ä¹ ä¼˜åŒ–å­—æ®µé€‰æ‹©
        optimized_fields = self.extraction_rl_agent.select_best_fields(
            [rule_results, ml_results, pattern_results],
            quality_scores,
            session_id
        )
        
        # 4. æ•°æ®æ¸…æ´—å’Œæ ‡å‡†åŒ–
        cleaned_fields = self._clean_and_standardize(optimized_fields)
        
        return cleaned_fields
        
    def learn_from_extraction_feedback(self, feedback_data):
        """ä»æå–åé¦ˆä¸­å­¦ä¹ """
        
        # æ›´æ–°å­—æ®µè´¨é‡è¯„ä¼°æ¨¡å‹
        self.field_quality_assessor.update_quality_model(feedback_data)
        
        # è®­ç»ƒå¼ºåŒ–å­¦ä¹ æ™ºèƒ½ä½“
        reward = self._calculate_extraction_reward(feedback_data)
        self.extraction_rl_agent.update_policy(feedback_data, reward)

class RLCoordinator:
    """å…¨å±€å¼ºåŒ–å­¦ä¹ åè°ƒå™¨"""
    
    def __init__(self, config_manager):
        self.config = config_manager
        self.global_rl_agent = GlobalRLAgent()
        
    def optimize_results(self, classification_results, matching_results, 
                        extracted_params, session_id):
        """å…¨å±€ä¼˜åŒ– - åè°ƒä¸‰å¤§æ¨¡å—ç»“æœ"""
        
        # 1. æ„å»ºå…¨å±€çŠ¶æ€
        global_state = self._build_global_state(
            classification_results, matching_results, extracted_params
        )
        
        # 2. å…¨å±€å†³ç­–
        global_action = self.global_rl_agent.select_global_action(
            global_state, session_id
        )
        
        # 3. åº”ç”¨å…¨å±€ä¼˜åŒ–ç­–ç•¥
        final_recommendations = self._apply_global_optimization(
            classification_results, 
            matching_results,
            global_action
        )
        
        return final_recommendations
```
        
    def _validate_feedback(self, feedback_data):
        """éªŒè¯åé¦ˆæ•°æ®å®Œæ•´æ€§å’Œåˆç†æ€§"""
        
        required_fields = ['session_id', 'material_info', 'user_feedback']
        for field in required_fields:
            if field not in feedback_data:
                raise ValueError(f"Missing required field: {field}")
                
        # éªŒè¯ç½®ä¿¡åº¦è¯„åˆ†èŒƒå›´
        confidence_rating = feedback_data['user_feedback'].get('confidence_rating')
        if confidence_rating and not (1 <= confidence_rating <= 10):
            raise ValueError("Confidence rating must be between 1 and 10")
            
        return feedback_data
        
    def _update_rules_immediately(self, feedback_data):
        """åŸºäºåé¦ˆå³æ—¶æ›´æ–°è§„åˆ™å¼•æ“"""
        
        material_name = feedback_data['material_info']['name']
        selected_category = feedback_data['user_feedback']['selected_category']
        
        # æå–å…³é”®è¯å¹¶æ›´æ–°è¯å…¸
        keywords = self._extract_keywords(material_name)
        for keyword in keywords:
            self.learning_system.rule_engine.update_keyword_mapping(
                keyword, selected_category, weight=0.1
            )
            
        # æ›´æ–°åˆ¶é€ å•†ä¿¡æ¯
        manufacturer = feedback_data['material_info'].get('manufacturer')
        if manufacturer:
            self.learning_system.rule_engine.update_manufacturer_mapping(
                manufacturer, selected_category
            )
```

## ğŸ¯ å­¦ä¹ ç­–ç•¥è®¾è®¡

### 1. å¤šç»´åº¦å­¦ä¹ æ–¹æ¡ˆ

#### å®æ—¶è§„åˆ™æ›´æ–°
- **å…³é”®è¯æƒé‡è°ƒæ•´**: æ ¹æ®ç”¨æˆ·åé¦ˆåŠ¨æ€è°ƒæ•´å…³é”®è¯-åˆ†ç±»æ˜ å°„æƒé‡
- **è§„æ ¼æ¨¡å¼ä¼˜åŒ–**: è‡ªåŠ¨å‘ç°æ–°çš„è§„æ ¼æ¨¡å¼å¹¶æ·»åŠ åˆ°æ­£åˆ™è¡¨è¾¾å¼åº“
- **åˆ¶é€ å•†ä¿¡èª‰åº¦æ›´æ–°**: åŸºäºåé¦ˆå»ºç«‹åˆ¶é€ å•†-åˆ†ç±»å¯é æ€§è¯„åˆ†

#### å¢é‡æ¨¡å‹è®­ç»ƒ
- **è§¦å‘æ¡ä»¶**: ç´¯ç§¯50æ¡æ–°åé¦ˆæˆ–æ¯å‘¨å®šæ—¶è§¦å‘
- **è®­ç»ƒç­–ç•¥**: ä½¿ç”¨åœ¨çº¿å­¦ä¹ ç®—æ³•ï¼Œé¿å…ç¾éš¾æ€§é—å¿˜
- **éªŒè¯æœºåˆ¶**: 20%æ•°æ®ç”¨äºéªŒè¯ï¼Œç¡®ä¿æ¨¡å‹æ€§èƒ½ä¸é€€åŒ–

#### å¼ºåŒ–å­¦ä¹ ä¼˜åŒ–
- **å¥–åŠ±å‡½æ•°è®¾è®¡**:
  ```python
  def calculate_reward(prediction, user_feedback):
      """è®¡ç®—å¼ºåŒ–å­¦ä¹ å¥–åŠ±"""
      base_reward = 1.0 if user_feedback['feedback_type'] == 'accept' else -0.5
      
      # ç½®ä¿¡åº¦åŒ¹é…å¥–åŠ±
      confidence_diff = abs(prediction['confidence'] - user_feedback['confidence_rating']/10)
      confidence_penalty = confidence_diff * 0.3
      
      # åˆ†ç±»å‡†ç¡®æ€§å¥–åŠ±
      category_match = prediction['category'] == user_feedback['selected_category']
      category_reward = 2.0 if category_match else -1.0
      
      return base_reward + category_reward - confidence_penalty
  ```

- **æ¢ç´¢ç­–ç•¥**: Îµ-è´ªå¿ƒç®—æ³•ï¼ŒåˆæœŸæ¢ç´¢æ€§å¼ºï¼ŒåæœŸè¶‹äºç¨³å®š
- **çŠ¶æ€è¡¨ç¤º**: ç‰©æ–™ç‰¹å¾å‘é‡ + å†å²åé¦ˆæ¨¡å¼

### 2. è·¨ç®—æ³•æ¨¡å—çš„ç»Ÿä¸€å­¦ä¹ ç­–ç•¥

#### å…¨å±€å¥–åŠ±å‡½æ•°è®¾è®¡
```python
def calculate_global_reward(feedback_data, system_metrics):
    """è®¡ç®—å…¨å±€ç³»ç»Ÿå¥–åŠ±"""
    
    # === åŸºç¡€å‡†ç¡®æ€§å¥–åŠ± ===
    accuracy_reward = 0
    if feedback_data.get('classification_correct'):
        accuracy_reward += 2.0
    if feedback_data.get('matching_successful'): 
        accuracy_reward += 1.5
    if feedback_data.get('extraction_accurate'):
        accuracy_reward += 1.0
        
    # === æ•ˆç‡å¥–åŠ± ===
    processing_time = system_metrics.get('processing_time', 1000)
    efficiency_reward = max(0, (1000 - processing_time) / 1000 * 0.5)
    
    # === ç”¨æˆ·ä½“éªŒå¥–åŠ± ===
    user_satisfaction = feedback_data.get('overall_satisfaction', 5)
    ux_reward = (user_satisfaction - 5) * 0.3
    
    # === ä¸€è‡´æ€§å¥–åŠ± ===
    # å¥–åŠ±ä¸‰ä¸ªæ¨¡å—ç»“æœçš„ä¸€è‡´æ€§
    consistency_score = calculate_cross_module_consistency(feedback_data)
    consistency_reward = consistency_score * 0.4
    
    # === å­¦ä¹ è¿›æ­¥å¥–åŠ± ===  
    improvement_rate = system_metrics.get('week_over_week_improvement', 0)
    progress_reward = improvement_rate * 0.2
    
    total_reward = (accuracy_reward + efficiency_reward + 
                   ux_reward + consistency_reward + progress_reward)
                   
    return total_reward

def calculate_cross_module_consistency(feedback_data):
    """è®¡ç®—è·¨æ¨¡å—ä¸€è‡´æ€§å¾—åˆ†"""
    
    # æ£€æŸ¥åˆ†ç±»å’ŒåŒ¹é…ç»“æœçš„ä¸€è‡´æ€§
    classification_category = feedback_data.get('selected_classification')
    matched_item_category = feedback_data.get('matched_item_category')
    
    if classification_category == matched_item_category:
        consistency_score = 1.0
    elif are_categories_related(classification_category, matched_item_category):
        consistency_score = 0.7
    else:
        consistency_score = 0.3
        
    # æ£€æŸ¥æå–å‚æ•°å’Œæœ€ç»ˆé€‰æ‹©çš„ä¸€è‡´æ€§
    extracted_specs = feedback_data.get('extracted_specifications')
    final_specs = feedback_data.get('user_confirmed_specifications')
    
    spec_consistency = calculate_spec_similarity(extracted_specs, final_specs)
    
    return (consistency_score + spec_consistency) / 2
```

#### å¤šç›®æ ‡ä¼˜åŒ–ç­–ç•¥
```python
class MultiObjectiveOptimizer:
    """å¤šç›®æ ‡ä¼˜åŒ–å™¨ - å¹³è¡¡å‡†ç¡®æ€§ã€æ•ˆç‡ã€ç”¨æˆ·æ»¡æ„åº¦"""
    
    def __init__(self):
        self.objectives = {
            'accuracy': {'weight': 0.5, 'target': 0.85},
            'efficiency': {'weight': 0.3, 'target': 500},  # ms
            'user_satisfaction': {'weight': 0.2, 'target': 8.0}  # 1-10 scale
        }
        
    def optimize_system_parameters(self, current_metrics):
        """ä¼˜åŒ–ç³»ç»Ÿå‚æ•°ä»¥å¹³è¡¡å¤šä¸ªç›®æ ‡"""
        
        # è®¡ç®—å½“å‰æ€§èƒ½è·ç¦»ç›®æ ‡çš„å·®è·
        gaps = {}
        for objective, config in self.objectives.items():
            current_value = current_metrics.get(objective, 0)
            target_value = config['target']
            gaps[objective] = abs(current_value - target_value) / target_value
            
        # è¯†åˆ«æœ€éœ€è¦æ”¹è¿›çš„ç›®æ ‡
        priority_objective = max(gaps.items(), key=lambda x: x[1])[0]
        
        # è°ƒæ•´ç®—æ³•æƒé‡
        if priority_objective == 'accuracy':
            return self._optimize_for_accuracy()
        elif priority_objective == 'efficiency': 
            return self._optimize_for_efficiency()
        else:
            return self._optimize_for_user_satisfaction()
            
    def _optimize_for_accuracy(self):
        """ä¼˜åŒ–å‡†ç¡®æ€§ - å¢åŠ MLæ¨¡å‹æƒé‡ï¼Œå‡å°‘å¿«é€Ÿç®—æ³•æƒé‡"""
        return {
            'classification_weights': {'rule': 0.3, 'ml': 0.5, 'rl': 0.2},
            'matching_weights': {'exact': 1.0, 'similarity': 0.9, 'fuzzy': 0.4},
            'extraction_weights': {'rule': 0.3, 'ml': 0.5, 'rl': 0.2}
        }
        
    def _optimize_for_efficiency(self):
        """ä¼˜åŒ–æ•ˆç‡ - å¢åŠ è§„åˆ™ç®—æ³•æƒé‡ï¼Œå‡å°‘å¤æ‚è®¡ç®—"""
        return {
            'classification_weights': {'rule': 0.6, 'ml': 0.2, 'rl': 0.2},
            'matching_weights': {'exact': 1.0, 'similarity': 0.6, 'fuzzy': 0.3},
            'extraction_weights': {'rule': 0.7, 'ml': 0.2, 'rl': 0.1}
        }
```

#### è‡ªé€‚åº”å­¦ä¹ æœºåˆ¶
```python
class AdaptiveLearningController:
    """è‡ªé€‚åº”å­¦ä¹ æ§åˆ¶å™¨"""
    
    def __init__(self):
        self.learning_phases = {
            'exploration': {'duration': 100, 'epsilon': 0.3},  # æ¢ç´¢æœŸ
            'exploitation': {'duration': 500, 'epsilon': 0.1}, # åˆ©ç”¨æœŸ  
            'refinement': {'duration': 1000, 'epsilon': 0.05}  # ç²¾åŒ–æœŸ
        }
        self.current_phase = 'exploration'
        self.phase_counter = 0
        
    def adjust_learning_strategy(self, feedback_count, performance_metrics):
        """æ ¹æ®åé¦ˆæ•°é‡å’Œæ€§èƒ½åŠ¨æ€è°ƒæ•´å­¦ä¹ ç­–ç•¥"""
        
        # æ›´æ–°å­¦ä¹ é˜¶æ®µ
        self._update_learning_phase(feedback_count)
        
        # æ ¹æ®å½“å‰é˜¶æ®µè°ƒæ•´å‚æ•°
        phase_config = self.learning_phases[self.current_phase]
        
        # è°ƒæ•´æ¢ç´¢ç‡
        epsilon = phase_config['epsilon']
        
        # æ ¹æ®æ€§èƒ½è°ƒæ•´å­¦ä¹ ç‡
        if performance_metrics.get('accuracy', 0) > 0.8:
            learning_rate = 0.01  # é«˜å‡†ç¡®ç‡æ—¶é™ä½å­¦ä¹ ç‡
        else:
            learning_rate = 0.1   # ä½å‡†ç¡®ç‡æ—¶æé«˜å­¦ä¹ ç‡
            
        return {
            'epsilon': epsilon,
            'learning_rate': learning_rate,
            'batch_size': self._calculate_batch_size(feedback_count),
            'update_frequency': self._calculate_update_frequency(performance_metrics)
        }
```

### 3. æ¨¡å‹ç‰ˆæœ¬ç®¡ç†

```python
class ModelVersionManager:
    """æ¨¡å‹ç‰ˆæœ¬ç®¡ç†ç³»ç»Ÿ"""
    
    def __init__(self, db_manager):
        self.db = db_manager
        
    def deploy_new_model(self, model_path, model_type, performance_metrics):
        """éƒ¨ç½²æ–°æ¨¡å‹ç‰ˆæœ¬"""
        
        # 1. éªŒè¯æ¨¡å‹æ€§èƒ½
        if not self._validate_performance(performance_metrics):
            raise ValueError("New model performance below threshold")
            
        # 2. åˆ›å»ºæ–°ç‰ˆæœ¬è®°å½•
        version_name = self._generate_version_name()
        
        # 3. A/Bæµ‹è¯•éƒ¨ç½²
        self._deploy_ab_test(model_path, version_name)
        
        # 4. ç›‘æ§æ€§èƒ½æŒ‡æ ‡
        self._start_performance_monitoring(version_name)
        
        return version_name
        
    def rollback_model(self, target_version=None):
        """æ¨¡å‹å›æ»šæœºåˆ¶"""
        
        if target_version is None:
            # å›æ»šåˆ°ä¸Šä¸€ä¸ªç¨³å®šç‰ˆæœ¬
            target_version = self._get_last_stable_version()
            
        # æ›´æ–°æ´»è·ƒæ¨¡å‹æ ‡è®°
        self.db.execute("""
            UPDATE model_versions 
            SET is_active = 0 
            WHERE is_active = 1
        """)
        
        self.db.execute("""
            UPDATE model_versions 
            SET is_active = 1 
            WHERE version_name = ?
        """, (target_version,))
        
        return target_version
```

## ğŸš¦ å®æ–½è·¯çº¿å›¾

### é˜¶æ®µ1: åŸºç¡€è®¾æ–½å»ºè®¾ (1-2å‘¨)
**ç›®æ ‡**: å»ºç«‹åé¦ˆæ”¶é›†å’Œå­˜å‚¨åŸºç¡€è®¾æ–½

**ä»»åŠ¡æ¸…å•**:
- [ ] æ‰©å±•æ•°æ®åº“è¡¨ç»“æ„ (user_feedback, training_samplesç­‰)
- [ ] å¼€å‘åé¦ˆæ”¶é›†APIæ¥å£
- [ ] å®ç°å‰ç«¯åé¦ˆç•Œé¢ç»„ä»¶
- [ ] å»ºç«‹æ•°æ®éªŒè¯å’Œæ¸…ç†æµç¨‹
- [ ] é…ç½®ç›‘æ§å’Œæ—¥å¿—ç³»ç»Ÿ

**éªŒæ”¶æ ‡å‡†**:
- ç”¨æˆ·å¯ä»¥åœ¨ç•Œé¢ä¸Šæäº¤åˆ†ç±»åé¦ˆ
- åé¦ˆæ•°æ®æ­£ç¡®å­˜å‚¨åˆ°æ•°æ®åº“
- åŸºç¡€ç›‘æ§æŒ‡æ ‡å¼€å§‹æ”¶é›†

### é˜¶æ®µ2: è§„åˆ™å¼•æ“å¢å¼º (2-3å‘¨)  
**ç›®æ ‡**: å¿«é€Ÿæå‡ç°æœ‰è§„åˆ™å¼•æ“æ€§èƒ½

**ä»»åŠ¡æ¸…å•**:
- [ ] æ‰©å……å…³é”®è¯è¯å…¸ (åŒ»ç–—å™¨æ¢°ã€å»ºæã€åŠå…¬ç”¨å“ç­‰)
- [ ] ä¼˜åŒ–è§„æ ¼æ¨¡å¼è¯†åˆ«æ­£åˆ™è¡¨è¾¾å¼
- [ ] å®Œå–„åˆ†ç±»ä½“ç³»å±‚æ¬¡ç»“æ„
- [ ] å®ç°åŠ¨æ€è§„åˆ™æƒé‡è°ƒæ•´
- [ ] æ·»åŠ åˆ¶é€ å•†ä¿¡èª‰è¯„åˆ†

**é¢„æœŸæ•ˆæœ**:
- æ¨èè¦†ç›–ç‡: 80% â†’ 90%
- ä¸­ç­‰ç½®ä¿¡åº¦æ¨è: 12.5% â†’ 30%

### é˜¶æ®µ3: æœºå™¨å­¦ä¹ é›†æˆ (3-4å‘¨)
**ç›®æ ‡**: å¼•å…¥MLæ¨¡å‹æå‡è¯­ä¹‰ç†è§£èƒ½åŠ›

**ä»»åŠ¡æ¸…å•**:
- [ ] è®­ç»ƒæ–‡æœ¬ç›¸ä¼¼åº¦æ¨¡å‹ (åŸºäºBERTä¸­æ–‡ç‰ˆ)
- [ ] å®ç°ç‰¹å¾å·¥ç¨‹pipeline
- [ ] å¼€å‘æ¨¡å‹é›†æˆæ¡†æ¶
- [ ] å»ºç«‹æ¨¡å‹è®­ç»ƒå’ŒéªŒè¯æµç¨‹
- [ ] å®ç°A/Bæµ‹è¯•æœºåˆ¶

**é¢„æœŸæ•ˆæœ**:
- æ¨èè¦†ç›–ç‡: 90% â†’ 95%
- é«˜ç½®ä¿¡åº¦æ¨è: 0% â†’ 25%

### é˜¶æ®µ4: å¼ºåŒ–å­¦ä¹ éƒ¨ç½² (4-6å‘¨)
**ç›®æ ‡**: å®ç°è‡ªé€‚åº”å­¦ä¹ å’ŒæŒç»­ä¼˜åŒ–

**ä»»åŠ¡æ¸…å•**:
- [ ] å¼€å‘å¼ºåŒ–å­¦ä¹ æ™ºèƒ½ä½“
- [ ] å®ç°åœ¨çº¿å­¦ä¹ æœºåˆ¶  
- [ ] å»ºç«‹æ¨¡å‹ç‰ˆæœ¬ç®¡ç†ç³»ç»Ÿ
- [ ] éƒ¨ç½²æ€§èƒ½ç›‘æ§å’Œå‘Šè­¦
- [ ] å®Œå–„åé¦ˆå¾ªç¯é—­ç¯

**é¢„æœŸæ•ˆæœ**:
- ç”¨æˆ·æ»¡æ„åº¦: 70% â†’ 85%
- ç³»ç»Ÿè‡ªé€‚åº”èƒ½åŠ›æ˜¾è‘—æå‡

## ğŸ”§ ä¸ç°æœ‰ç³»ç»Ÿé›†æˆç‚¹

### æ•°æ®åº“é›†æˆ
- **æ‰©å±•ç­–ç•¥**: åœ¨ç°æœ‰ `business_data.db` åŸºç¡€ä¸Šæ·»åŠ æ–°è¡¨
- **ä¼šè¯ç®¡ç†**: å¤ç”¨ `session_manager` è¿›è¡Œä¼šè¯è·Ÿè¸ª
- **ä¸»æ•°æ®é›†æˆ**: ä¸ `master_data_manager` æ— ç¼å¯¹æ¥

### APIé›†æˆ  
- **è·¯ç”±æ‰©å±•**: åœ¨ç°æœ‰Flaskåº”ç”¨åŸºç¡€ä¸Šæ·»åŠ æ–°çš„APIç«¯ç‚¹
- **è®¤è¯å¤ç”¨**: ä½¿ç”¨ç°æœ‰çš„ä¼šè¯è®¤è¯æœºåˆ¶
- **é”™è¯¯å¤„ç†**: ç»Ÿä¸€çš„å¼‚å¸¸å¤„ç†å’Œå“åº”æ ¼å¼

### ç®—æ³•é›†æˆ
- **æ¸è¿›å¼å‡çº§**: ä¿ç•™ç°æœ‰ `intelligent_classifier.py`ï¼Œæ¸è¿›å¼•å…¥æ–°ç®—æ³•
- **æ— ç¼åˆ‡æ¢**: é€šè¿‡é…ç½®å‚æ•°æ§åˆ¶ç®—æ³•ç‰ˆæœ¬åˆ‡æ¢
- **å‘åå…¼å®¹**: ç¡®ä¿æ–°ç®—æ³•ä¸ç°æœ‰æ¥å£å®Œå…¨å…¼å®¹
- **è·¨æ¨¡å—å­¦ä¹ **: ç»Ÿä¸€çš„å¢å¼ºå­¦ä¹ æ¡†æ¶åè°ƒåˆ†ç±»ã€åŒ¹é…ã€æå–ä¸‰å¤§æ¨¡å—
- **æ™ºèƒ½è°ƒåº¦**: æ ¹æ®ä»»åŠ¡ç±»å‹å’Œç”¨æˆ·åå¥½åŠ¨æ€é€‰æ‹©æœ€ä¼˜ç®—æ³•ç»„åˆ

#### å…·ä½“æ•´åˆæ–¹æ¡ˆ

**1. ç°æœ‰ç³»ç»Ÿæ”¹é€ **
```python
# æ‰©å±•ç°æœ‰ intelligent_classifier.py
class IntelligentClassifier:
    def __init__(self, master_data_manager, enhanced_learning=False):
        # ä¿ç•™åŸæœ‰åŠŸèƒ½
        self.master_data_manager = master_data_manager
        self.keyword_mappings = {...}  # ç°æœ‰å…³é”®è¯æ˜ å°„
        
        # æ–°å¢å¢å¼ºå­¦ä¹ åŠŸèƒ½
        if enhanced_learning:
            self.rl_system = EnhancedLearningSystem(config_manager, db_manager)
            self.use_rl = True
        else:
            self.use_rl = False
            
    def recommend_categories(self, material_features, session_id):
        """å…¼å®¹åŸæ¥å£çš„æ™ºèƒ½æ¨è"""
        if self.use_rl:
            # ä½¿ç”¨æ–°çš„å¢å¼ºå­¦ä¹ ç³»ç»Ÿ
            return self.rl_system.unified_intelligent_processing(
                [material_features], session_id
            )[0]['recommendations']
        else:
            # ä½¿ç”¨åŸæœ‰ç®—æ³•
            return self._original_recommend_categories(material_features)
```

**2. æ™ºèƒ½åŒ¹é…æ¨¡å—æ•´åˆ**
```python
# æ‰©å±•ç°æœ‰åŒ¹é…åŠŸèƒ½
class AdvancedMatcher:
    def __init__(self, config, enhanced_learning=False):
        # ä¿ç•™ç°æœ‰é«˜çº§åŒ¹é…å™¨åŠŸèƒ½
        self.config = config
        self.similarity_calculator = SimilarityCalculator()
        
        # æ–°å¢å¢å¼ºå­¦ä¹ åŒ¹é…
        if enhanced_learning:
            self.matching_engine = IntelligentMatchingEngine(config)
            self.use_rl_matching = True
        else:
            self.use_rl_matching = False
            
    def find_matches(self, new_item, master_data, threshold=0.8):
        """å¢å¼ºçš„åŒ¹é…åŠŸèƒ½"""
        if self.use_rl_matching:
            # ä½¿ç”¨RLå¢å¼ºåŒ¹é…
            return self.matching_engine.find_matches_with_rl(
                new_item, session_id=None
            )
        else:
            # ä½¿ç”¨åŸæœ‰åŒ¹é…é€»è¾‘
            return self._original_find_matches(new_item, master_data, threshold)
```

**3. å‚æ•°æå–æ¨¡å—æ•´åˆ**
```python
# åœ¨ workflow_service.py ä¸­æ•´åˆ
class WorkflowService:
    def __init__(self, config, enhanced_learning=False):
        self.config = config
        
        # ç°æœ‰ç»„ä»¶
        self.preprocessor = AdvancedPreprocessor(config)
        self.matcher = AdvancedMatcher(config, enhanced_learning)
        
        # æ–°å¢å¢å¼ºå­¦ä¹ å‚æ•°æå–
        if enhanced_learning:
            self.extraction_engine = ParameterExtractionEngine(config)
            self.use_rl_extraction = True
        else:
            self.use_rl_extraction = False
            
    def process_file(self, file_path, session_id):
        """å¢å¼ºçš„æ–‡ä»¶å¤„ç†æµç¨‹"""
        
        # 1. æ•°æ®é¢„å¤„ç† (ä¿ç•™åŸæœ‰)
        processed_data = self.preprocessor.process_file(file_path)
        
        # 2. å‚æ•°æå– (å¯é€‰æ‹©RLå¢å¼º)
        if self.use_rl_extraction:
            extracted_params = []
            for row in processed_data:
                params = self.extraction_engine.extract_and_optimize(
                    row, session_id
                )
                extracted_params.append(params)
        else:
            extracted_params = processed_data
            
        # 3. æ™ºèƒ½åŒ¹é… (å¯é€‰æ‹©RLå¢å¼º)
        matching_results = []
        for params in extracted_params:
            matches = self.matcher.find_matches(params, self.master_data)
            matching_results.append(matches)
            
        return matching_results
```

## ğŸ“ˆ æ€§èƒ½æŒ‡æ ‡ä¸ç›‘æ§

### æ ¸å¿ƒKPIå®šä¹‰
- **æ¨èå‡†ç¡®ç‡**: (æ­£ç¡®æ¨èæ•° / æ€»æ¨èæ•°) â‰¥ 85%
- **ç”¨æˆ·æ¥å—ç‡**: (ç”¨æˆ·æ¥å—æ¨èæ•° / æ€»æ¨èæ•°) â‰¥ 70%  
- **å¹³å‡ç½®ä¿¡åº¦**: æ‰€æœ‰æ¨èçš„å¹³å‡ç½®ä¿¡åº¦ â‰¥ 75%
- **ç³»ç»Ÿå“åº”æ—¶é—´**: APIå“åº”æ—¶é—´ < 500ms
- **æ¨¡å‹è¦†ç›–ç‡**: èƒ½å¤Ÿç»™å‡ºæ¨èçš„ç‰©æ–™æ¯”ä¾‹ â‰¥ 95%

### ç›‘æ§ç»´åº¦è®¾è®¡

#### å®æ—¶ç›‘æ§
```python
# æ¯å°æ—¶ç»Ÿè®¡çš„å…³é”®æŒ‡æ ‡
REALTIME_METRICS = {
    'prediction_count': 0,
    'success_rate': 0.0,
    'avg_confidence': 0.0,
    'response_time_p95': 0.0,
    'error_count': 0
}

# ç›‘æ§å‘Šè­¦é˜ˆå€¼
ALERT_THRESHOLDS = {
    'success_rate_min': 0.7,
    'avg_confidence_min': 0.6,
    'response_time_max': 1000,  # ms
    'error_rate_max': 0.05
}
```

#### ç”¨æˆ·è¡Œä¸ºç›‘æ§
- åé¦ˆæäº¤é¢‘ç‡å’Œç±»å‹åˆ†å¸ƒ
- ä¼šè¯çº§åˆ«çš„æ¨èæ•ˆæœè·Ÿè¸ª
- ç”¨æˆ·æ»¡æ„åº¦è¶‹åŠ¿åˆ†æ

#### æ¨¡å‹æ€§èƒ½ç›‘æ§  
- å„ç®—æ³•ç»„ä»¶è´¡çŒ®åº¦åˆ†æ
- æ¨¡å‹æ¼‚ç§»æ£€æµ‹å’Œå‘Šè­¦
- A/Bæµ‹è¯•æ•ˆæœå¯¹æ¯”

## ğŸ›¡ï¸ é£é™©æ§åˆ¶å’Œè´¨é‡ä¿è¯

### æ¨¡å‹è´¨é‡ä¿è¯
```python
class ModelQualityController:
    """æ¨¡å‹è´¨é‡æ§åˆ¶å™¨"""
    
    def __init__(self, config):
        self.min_accuracy_threshold = config.get('min_accuracy', 0.75)
        self.max_degradation_rate = config.get('max_degradation', 0.05)
        
    def validate_model_deployment(self, new_model_metrics, current_metrics):
        """éªŒè¯æ–°æ¨¡å‹æ˜¯å¦å¯ä»¥éƒ¨ç½²"""
        
        # å‡†ç¡®ç‡ä¸èƒ½ä½äºé˜ˆå€¼
        if new_model_metrics['accuracy'] < self.min_accuracy_threshold:
            return False, "Accuracy below minimum threshold"
            
        # æ€§èƒ½ä¸èƒ½æ˜¾è‘—é€€åŒ–
        accuracy_drop = current_metrics['accuracy'] - new_model_metrics['accuracy']
        if accuracy_drop > self.max_degradation_rate:
            return False, "Significant performance degradation detected"
            
        return True, "Model validation passed"
```

### æ•°æ®å®‰å…¨å’Œéšç§
- ç”¨æˆ·åé¦ˆæ•°æ®è„±æ•å¤„ç†
- æ¨¡å‹è®­ç»ƒæ•°æ®è®¿é—®æ§åˆ¶
- æ•æ„Ÿä¿¡æ¯åŠ å¯†å­˜å‚¨

### ç³»ç»Ÿç¨³å®šæ€§
- æ¸è¿›å¼éƒ¨ç½²ï¼Œé¿å…å¤§è§„æ¨¡æ•…éšœ
- è‡ªåŠ¨å›æ»šæœºåˆ¶ï¼Œç¡®ä¿æœåŠ¡å¯ç”¨æ€§
- é™æµå’Œç†”æ–­ä¿æŠ¤

## ğŸ“ å¼€å‘è§„èŒƒå’Œæœ€ä½³å®è·µ

### ä»£ç ç»„ç»‡ç»“æ„
```
app/
â”œâ”€â”€ ml_engine/              # æœºå™¨å­¦ä¹ å¼•æ“
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ base_classifier.py   # åŸºç¡€åˆ†ç±»å™¨æ¥å£
â”‚   â”œâ”€â”€ ml_classifier.py     # MLæ¨¡å‹å®ç°
â”‚   â”œâ”€â”€ ensemble_classifier.py # é›†æˆåˆ†ç±»å™¨
â”‚   â””â”€â”€ feature_engineering.py # ç‰¹å¾å·¥ç¨‹
â”œâ”€â”€ reinforcement/           # å¼ºåŒ–å­¦ä¹ æ¨¡å—  
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ rl_agent.py         # RLæ™ºèƒ½ä½“
â”‚   â”œâ”€â”€ reward_calculator.py # å¥–åŠ±è®¡ç®—
â”‚   â””â”€â”€ experience_replay.py # ç»éªŒå›æ”¾
â”œâ”€â”€ feedback/               # åé¦ˆå¤„ç†æ¨¡å—
â”‚   â”œâ”€â”€ __init__.py  
â”‚   â”œâ”€â”€ feedback_processor.py # åé¦ˆå¤„ç†å™¨
â”‚   â”œâ”€â”€ data_validator.py    # æ•°æ®éªŒè¯
â”‚   â””â”€â”€ learning_trigger.py  # å­¦ä¹ è§¦å‘å™¨
â””â”€â”€ monitoring/             # ç›‘æ§æ¨¡å—
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ metrics_collector.py # æŒ‡æ ‡æ”¶é›†
    â”œâ”€â”€ performance_monitor.py # æ€§èƒ½ç›‘æ§
    â””â”€â”€ alert_manager.py     # å‘Šè­¦ç®¡ç†
```

### é…ç½®ç®¡ç†
```python
# config/enhanced_learning_config.py
ENHANCED_LEARNING_CONFIG = {
    # === å…¨å±€å¼€å…³ ===
    'enable_enhanced_learning': True,  # ä¸»å¼€å…³
    'modules': {
        'classification_rl': True,     # æ™ºèƒ½åˆ†ç±»RL
        'matching_rl': True,          # æ™ºèƒ½åŒ¹é…RL  
        'extraction_rl': True,        # å‚æ•°æå–RL
        'global_coordination': True    # å…¨å±€åè°ƒRL
    },
    
    # === ç®—æ³•æƒé‡é…ç½® ===
    'algorithm_weights': {
        'classification': {
            'rule_based': 0.4,
            'ml_model': 0.4,
            'rl_adjustment': 0.2
        },
        'matching': {
            'exact_match': 1.0,
            'similarity': 0.8,
            'fuzzy': 0.6,
            'history': 0.7,
            'user_preference': 0.5
        },
        'extraction': {
            'rule_based': 0.5,
            'ml_model': 0.3,
            'pattern_matching': 0.2
        }
    },
    
    # === RLè®­ç»ƒå‚æ•° ===
    'reinforcement_learning': {
        'classification_rl': {
            'epsilon': 0.1,           # æ¢ç´¢ç‡
            'learning_rate': 0.01,    # å­¦ä¹ ç‡
            'discount_factor': 0.9,   # æŠ˜æ‰£å› å­
            'experience_buffer_size': 1000
        },
        'matching_rl': {
            'epsilon': 0.15,          # åŒ¹é…å…è®¸æ›´å¤šæ¢ç´¢
            'learning_rate': 0.05,
            'discount_factor': 0.85,
            'user_preference_weight': 0.3
        },
        'global_rl': {
            'epsilon': 0.05,          # å…¨å±€å†³ç­–æ›´ä¿å®ˆ
            'learning_rate': 0.005,
            'multi_objective_weights': {
                'accuracy': 0.5,
                'efficiency': 0.3, 
                'user_satisfaction': 0.2
            }
        }
    },
    
    # === åé¦ˆå¤„ç†é…ç½® ===
    'feedback': {
        'min_samples_for_training': 50,
        'batch_training_interval': 7,     # å¤©
        'online_learning_threshold': 10,  # å³æ—¶å­¦ä¹ é˜ˆå€¼
        'feedback_weight_decay': 0.95,
        'quality_filter_threshold': 0.7   # åé¦ˆè´¨é‡è¿‡æ»¤
    },
    
    # === æ€§èƒ½ç›‘æ§é…ç½® ===
    'monitoring': {
        'performance_check_interval': 3600,  # ç§’
        'alert_thresholds': {
            'accuracy_drop': 0.05,           # å‡†ç¡®ç‡ä¸‹é™5%æŠ¥è­¦
            'response_time_increase': 200,    # å“åº”æ—¶é—´å¢åŠ 200msæŠ¥è­¦
            'user_satisfaction_drop': 0.5     # ç”¨æˆ·æ»¡æ„åº¦ä¸‹é™0.5æŠ¥è­¦
        },
        'auto_rollback': {
            'enable': True,
            'trigger_threshold': 0.1,         # æ€§èƒ½ä¸‹é™10%è‡ªåŠ¨å›æ»š
            'confirmation_samples': 20        # ç¡®è®¤æ ·æœ¬æ•°
        }
    }
}

# config/deployment_strategy.py  
DEPLOYMENT_STRATEGY = {
    # === æ¸è¿›å¼éƒ¨ç½²é…ç½® ===
    'rollout_phases': [
        {
            'name': 'alpha_testing',
            'user_percentage': 5,      # 5%ç”¨æˆ·
            'duration_days': 7,
            'success_criteria': {
                'accuracy': 0.75,
                'user_satisfaction': 7.0,
                'error_rate': 0.02
            }
        },
        {
            'name': 'beta_testing', 
            'user_percentage': 20,     # 20%ç”¨æˆ·
            'duration_days': 14,
            'success_criteria': {
                'accuracy': 0.80,
                'user_satisfaction': 7.5,
                'error_rate': 0.01
            }
        },
        {
            'name': 'full_deployment',
            'user_percentage': 100,    # å…¨é‡ç”¨æˆ·
            'duration_days': 30,
            'success_criteria': {
                'accuracy': 0.85,
                'user_satisfaction': 8.0,
                'error_rate': 0.005
            }
        }
    ],
    
    # === A/Bæµ‹è¯•é…ç½® ===
    'ab_testing': {
        'enable': True,
        'split_ratio': 0.5,           # 50/50åˆ†æµ
        'minimum_sample_size': 100,    # æœ€å°æ ·æœ¬æ•°
        'statistical_significance': 0.95,  # ç»Ÿè®¡æ˜¾è‘—æ€§
        'test_duration_days': 14
    }
}
```

### æ¸è¿›å¼éƒ¨ç½²å’ŒA/Bæµ‹è¯•æ¡†æ¶

```python
class DeploymentController:
    """éƒ¨ç½²æ§åˆ¶å™¨ - ç®¡ç†æ¸è¿›å¼å‘å¸ƒå’ŒA/Bæµ‹è¯•"""
    
    def __init__(self, config):
        self.config = config
        self.current_phase = 'alpha_testing'
        self.ab_test_manager = ABTestManager()
        
    def should_use_enhanced_learning(self, session_id):
        """å†³å®šå½“å‰ç”¨æˆ·æ˜¯å¦ä½¿ç”¨å¢å¼ºå­¦ä¹ åŠŸèƒ½"""
        
        # 1. æ£€æŸ¥å…¨å±€å¼€å…³
        if not self.config['enable_enhanced_learning']:
            return False
            
        # 2. æ£€æŸ¥éƒ¨ç½²é˜¶æ®µ
        phase_config = self._get_current_phase_config()
        user_percentage = phase_config['user_percentage']
        
        # 3. ç”¨æˆ·åˆ†ç»„ (åŸºäºsession_idçš„å“ˆå¸Œ)
        user_hash = hash(session_id) % 100
        if user_hash >= user_percentage:
            return False
            
        # 4. A/Bæµ‹è¯•åˆ†ç»„
        if self.config['ab_testing']['enable']:
            return self.ab_test_manager.assign_to_treatment_group(session_id)
            
        return True
        
    def collect_performance_metrics(self, session_id, metrics_data):
        """æ”¶é›†æ€§èƒ½æŒ‡æ ‡ç”¨äºè¯„ä¼°éƒ¨ç½²æ•ˆæœ"""
        
        # æ ‡è®°ç”¨æˆ·ç»„
        is_enhanced = self.should_use_enhanced_learning(session_id)
        metrics_data['user_group'] = 'enhanced' if is_enhanced else 'baseline'
        
        # å­˜å‚¨åˆ°ç›‘æ§ç³»ç»Ÿ
        self._store_metrics(metrics_data)
        
        # æ£€æŸ¥æ˜¯å¦éœ€è¦é˜¶æ®µå‡çº§æˆ–å›æ»š
        self._evaluate_phase_transition()

class ABTestManager:
    """A/Bæµ‹è¯•ç®¡ç†å™¨"""
    
    def __init__(self):
        self.test_assignments = {}  # ç”¨æˆ·æµ‹è¯•ç»„åˆ†é…
        
    def assign_to_treatment_group(self, session_id):
        """åˆ†é…ç”¨æˆ·åˆ°å®éªŒç»„æˆ–å¯¹ç…§ç»„"""
        
        if session_id in self.test_assignments:
            return self.test_assignments[session_id]
            
        # åŸºäºsession_idå“ˆå¸Œè¿›è¡Œéšæœºåˆ†ç»„
        assignment = (hash(session_id) % 2) == 0
        self.test_assignments[session_id] = assignment
        
        return assignment
        
    def analyze_test_results(self):
        """åˆ†æA/Bæµ‹è¯•ç»“æœ"""
        
        treatment_metrics = self._get_group_metrics('enhanced')
        control_metrics = self._get_group_metrics('baseline')
        
        # ç»Ÿè®¡æ˜¾è‘—æ€§æ£€éªŒ
        significance_test = self._statistical_significance_test(
            treatment_metrics, control_metrics
        )
        
        return {
            'treatment_group': treatment_metrics,
            'control_group': control_metrics,
            'statistical_significance': significance_test,
            'recommendation': self._get_deployment_recommendation(significance_test)
        }
```

## ğŸ‰ æˆåŠŸæŒ‡æ ‡å’Œé‡Œç¨‹ç¢‘

### çŸ­æœŸç›®æ ‡ (1ä¸ªæœˆ)
- [ ] æ¨èç½®ä¿¡åº¦å¹³å‡æå‡è‡³60%+
- [ ] ç”¨æˆ·åé¦ˆæ”¶é›†ç‡è¾¾åˆ°30%+  
- [ ] ç³»ç»Ÿå“åº”æ—¶é—´ä¿æŒåœ¨500msä»¥ä¸‹

### ä¸­æœŸç›®æ ‡ (3ä¸ªæœˆ)
- [ ] æ¨èå‡†ç¡®ç‡è¾¾åˆ°80%+
- [ ] ç”¨æˆ·æ»¡æ„åº¦è¾¾åˆ°75%+
- [ ] å®ç°å®Œå…¨è‡ªåŠ¨åŒ–çš„æ¨¡å‹æ›´æ–°

### é•¿æœŸç›®æ ‡ (6ä¸ªæœˆ)
- [ ] æ¨èå‡†ç¡®ç‡è¾¾åˆ°90%+
- [ ] ç”¨æˆ·æ»¡æ„åº¦è¾¾åˆ°85%+
- [ ] å»ºæˆä¸šç•Œé¢†å…ˆçš„æ™ºèƒ½åˆ†ç±»ç³»ç»Ÿ

---

## ğŸ“š æŠ€æœ¯æ ˆå’Œä¾èµ–

### æœºå™¨å­¦ä¹ æ¡†æ¶
- **scikit-learn**: ä¼ ç»ŸMLç®—æ³•
- **transformers**: é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹
- **torch**: æ·±åº¦å­¦ä¹ æ¡†æ¶
- **pandas**: æ•°æ®å¤„ç†

### æ•°æ®åº“å’Œå­˜å‚¨
- **SQLite**: è½»é‡çº§å…³ç³»æ•°æ®åº“  
- **Redis**: ç¼“å­˜å’Œä¼šè¯å­˜å‚¨
- **pickle**: æ¨¡å‹åºåˆ—åŒ–

### ç›‘æ§å’Œæ—¥å¿—
- **prometheus**: æŒ‡æ ‡æ”¶é›†
- **grafana**: å¯è§†åŒ–é¢æ¿
- **loguru**: ç»“æ„åŒ–æ—¥å¿—

### ç›‘æ§å’Œå›æ»šæœºåˆ¶

```python
class PerformanceMonitor:
    """æ€§èƒ½ç›‘æ§å™¨ - å®æ—¶ç›‘æ§ç³»ç»Ÿè¡¨ç°"""
    
    def __init__(self, config):
        self.config = config
        self.baseline_metrics = {}
        self.current_metrics = {}
        self.alert_manager = AlertManager()
        
    def monitor_system_performance(self):
        """ç›‘æ§ç³»ç»Ÿæ€§èƒ½æŒ‡æ ‡"""
        
        current_metrics = self._collect_current_metrics()
        
        # æ£€æŸ¥å…³é”®æŒ‡æ ‡
        alerts = []
        
        # å‡†ç¡®ç‡æ£€æŸ¥
        accuracy_drop = (
            self.baseline_metrics.get('accuracy', 0) - 
            current_metrics.get('accuracy', 0)
        )
        if accuracy_drop > self.config['monitoring']['alert_thresholds']['accuracy_drop']:
            alerts.append({
                'type': 'accuracy_degradation',
                'severity': 'high',
                'value': accuracy_drop
            })
            
        # å“åº”æ—¶é—´æ£€æŸ¥
        response_time_increase = (
            current_metrics.get('response_time', 0) - 
            self.baseline_metrics.get('response_time', 0)
        )
        if response_time_increase > self.config['monitoring']['alert_thresholds']['response_time_increase']:
            alerts.append({
                'type': 'performance_degradation',
                'severity': 'medium',
                'value': response_time_increase
            })
            
        # ç”¨æˆ·æ»¡æ„åº¦æ£€æŸ¥
        satisfaction_drop = (
            self.baseline_metrics.get('user_satisfaction', 0) - 
            current_metrics.get('user_satisfaction', 0)
        )
        if satisfaction_drop > self.config['monitoring']['alert_thresholds']['user_satisfaction_drop']:
            alerts.append({
                'type': 'user_experience_degradation',
                'severity': 'high', 
                'value': satisfaction_drop
            })
            
        # è§¦å‘æŠ¥è­¦å’Œè‡ªåŠ¨å›æ»š
        if alerts:
            self.alert_manager.send_alerts(alerts)
            
            # æ£€æŸ¥æ˜¯å¦éœ€è¦è‡ªåŠ¨å›æ»š
            if self._should_auto_rollback(current_metrics):
                self._trigger_rollback()
                
    def _should_auto_rollback(self, metrics):
        """åˆ¤æ–­æ˜¯å¦éœ€è¦è‡ªåŠ¨å›æ»š"""
        
        if not self.config['monitoring']['auto_rollback']['enable']:
            return False
            
        # è®¡ç®—ç»¼åˆæ€§èƒ½ä¸‹é™å¹…åº¦
        performance_drop = self._calculate_performance_drop(metrics)
        threshold = self.config['monitoring']['auto_rollback']['trigger_threshold']
        
        return performance_drop > threshold

class GradualRollbackManager:
    """æ¸è¿›å¼å›æ»šç®¡ç†å™¨"""
    
    def __init__(self):
        self.rollback_phases = [
            {'name': 'partial_rollback', 'percentage': 50},
            {'name': 'major_rollback', 'percentage': 80}, 
            {'name': 'full_rollback', 'percentage': 100}
        ]
        self.current_rollback_phase = 0
        
    def execute_rollback(self, severity='medium'):
        """æ‰§è¡Œæ¸è¿›å¼å›æ»š"""
        
        if severity == 'high':
            # é«˜ä¸¥é‡æ€§ç›´æ¥å…¨é‡å›æ»š
            self._rollback_to_baseline(100)
        else:
            # æ¸è¿›å¼å›æ»š
            phase = self.rollback_phases[self.current_rollback_phase]
            self._rollback_to_baseline(phase['percentage'])
            self.current_rollback_phase = min(
                self.current_rollback_phase + 1, 
                len(self.rollback_phases) - 1
            )
            
    def _rollback_to_baseline(self, percentage):
        """å›æ»šæŒ‡å®šæ¯”ä¾‹çš„æµé‡åˆ°åŸºçº¿ç‰ˆæœ¬"""
        
        # æ›´æ–°é…ç½®ï¼Œé™ä½å¢å¼ºå­¦ä¹ ä½¿ç”¨æ¯”ä¾‹
        current_config = get_current_config()
        current_config['modules']['classification_rl'] = percentage < 100
        current_config['modules']['matching_rl'] = percentage < 100
        current_config['modules']['extraction_rl'] = percentage < 100
        
        # è®°å½•å›æ»šæ“ä½œ
        log_rollback_operation(percentage, datetime.now())
```

## ğŸ“‹ å®Œæ•´å®æ–½è·¯çº¿å›¾

### ğŸš€ ç¬¬ä¸€é˜¶æ®µï¼šåŸºç¡€æ¶æ„æ­å»º (2-3å‘¨)
**ç›®æ ‡**: å»ºç«‹ç»Ÿä¸€å­¦ä¹ æ¡†æ¶å’Œæ ¸å¿ƒåŸºç¡€è®¾æ–½

**ä¸»è¦ä»»åŠ¡**:
1. **ç»Ÿä¸€å­¦ä¹ æ¡†æ¶**
   - [ ] å®ç° `UnifiedLearningFramework` åŸºç¡€ç±»
   - [ ] æ­å»ºè·¨æ¨¡å—é€šä¿¡æœºåˆ¶ (MessageBroker)
   - [ ] å»ºç«‹å…¨å±€çŠ¶æ€ç®¡ç† (GlobalStateManager)
   - [ ] å®ç°é…ç½®ç®¡ç†ç³»ç»Ÿ

2. **æ•°æ®åŸºç¡€è®¾æ–½**
   - [ ] æ‰©å±•æ•°æ®åº“è¡¨ç»“æ„ (feedbackè¡¨ï¼Œmetricsè¡¨ç­‰)
   - [ ] å®ç°åé¦ˆæ•°æ®æ”¶é›†API
   - [ ] å»ºç«‹è®­ç»ƒæ ·æœ¬ç®¡ç†ç³»ç»Ÿ
   - [ ] é…ç½®æ•°æ®å¤‡ä»½å’Œæ¢å¤æœºåˆ¶

3. **å¢å¼ºåˆ†ç±»æ¨¡å—å‡çº§**
   - [ ] é‡æ„ç°æœ‰ `intelligent_classifier.py`
   - [ ] é›†æˆå¼ºåŒ–å­¦ä¹ ç»„ä»¶ (EnhancedClassifier)
   - [ ] å®ç°å¤šç®—æ³•é›†æˆå†³ç­–
   - [ ] æ·»åŠ ç½®ä¿¡åº¦è¯„ä¼°æœºåˆ¶

**éªŒæ”¶æ ‡å‡†**:
- ç»Ÿä¸€æ¡†æ¶å¯ä»¥ç®¡ç†å¤šä¸ªRLæ™ºèƒ½ä½“
- ç”¨æˆ·åé¦ˆæ­£å¸¸æ”¶é›†å’Œå­˜å‚¨
- å¢å¼ºåˆ†ç±»å™¨å‡†ç¡®ç‡ä¸ä½äºç°æœ‰ç³»ç»Ÿ
- ç³»ç»Ÿå“åº”æ—¶é—´å¢åŠ ä¸è¶…è¿‡20%

### ğŸ¯ ç¬¬äºŒé˜¶æ®µï¼šæ™ºèƒ½åŒ¹é…å¢å¼º (3-4å‘¨)
**ç›®æ ‡**: å®ç°æ™ºèƒ½åŒ¹é…å¼•æ“å’Œå‚æ•°æå–å¼•æ“

**ä¸»è¦ä»»åŠ¡**:
1. **åŒ¹é…å¼•æ“é‡æ„**
   - [ ] å®ç° `IntelligentMatchingEngine`
   - [ ] æ·»åŠ å¤šç»´åº¦ç›¸ä¼¼åº¦è®¡ç®— (è¯­ä¹‰ã€ç»“æ„ã€å†å²)
   - [ ] é›†æˆç”¨æˆ·åå¥½å­¦ä¹ 
   - [ ] å®ç°åŠ¨æ€æƒé‡è°ƒæ•´

2. **å‚æ•°æå–å¢å¼º**
   - [ ] å®ç° `ParameterExtractionEngine`
   - [ ] æ·»åŠ ä¸Šä¸‹æ–‡æ„ŸçŸ¥æœºåˆ¶
   - [ ] ä¼˜åŒ–æ­£åˆ™è¡¨è¾¾å¼å’ŒMLæ¨¡å‹ç»“åˆ
   - [ ] å®ç°å‚æ•°éªŒè¯å’Œçº é”™

3. **è·¨æ¨¡å—åè°ƒ**
   - [ ] å®ç°æ¨¡å—é—´æ•°æ®å…±äº«
   - [ ] å»ºç«‹ä¸€è‡´æ€§æ£€æŸ¥æœºåˆ¶
   - [ ] æ·»åŠ å†³ç­–å†²çªè§£å†³ç­–ç•¥
   - [ ] å®ç°å…¨å±€ä¼˜åŒ–åé¦ˆ

**éªŒæ”¶æ ‡å‡†**:
- åŒ¹é…å‡†ç¡®ç‡æå‡15%+
- å‚æ•°æå–å‡†ç¡®ç‡æå‡10%+
- è·¨æ¨¡å—å†³ç­–ä¸€è‡´æ€§è¾¾åˆ°90%+
- ç”¨æˆ·åå¥½å­¦ä¹ æœ‰æ•ˆè¿è¡Œ

### âš¡ ç¬¬ä¸‰é˜¶æ®µï¼šå…¨å±€åè°ƒä¸ä¼˜åŒ– (2-3å‘¨)  
**ç›®æ ‡**: å®ç°ç³»ç»Ÿçº§åè°ƒå’Œå¤šç›®æ ‡ä¼˜åŒ–

**ä¸»è¦ä»»åŠ¡**:
1. **å…¨å±€åè°ƒå™¨**
   - [ ] å®ç° `RLCoordinator` æ ¸å¿ƒé€»è¾‘
   - [ ] å»ºç«‹å¤šç›®æ ‡ä¼˜åŒ–ç®—æ³•
   - [ ] å®ç°å…¨å±€ä¸€è‡´æ€§æ£€æŸ¥
   - [ ] æ·»åŠ æ€§èƒ½å¹³è¡¡æœºåˆ¶

2. **éƒ¨ç½²å’Œç›‘æ§ç³»ç»Ÿ**
   - [ ] å®ç°æ¸è¿›å¼éƒ¨ç½²æ§åˆ¶å™¨
   - [ ] å»ºç«‹A/Bæµ‹è¯•æ¡†æ¶ 
   - [ ] æ­å»ºæ€§èƒ½ç›‘æ§ç³»ç»Ÿ
   - [ ] å®ç°è‡ªåŠ¨å›æ»šæœºåˆ¶

3. **ç”¨æˆ·ä½“éªŒä¼˜åŒ–**
   - [ ] å®ç°å®æ—¶åé¦ˆæ”¶é›†
   - [ ] æ·»åŠ è§£é‡Šæ€§åŠŸèƒ½
   - [ ] ä¼˜åŒ–ç•Œé¢äº¤äº’ä½“éªŒ
   - [ ] å»ºç«‹ç”¨æˆ·æ»¡æ„åº¦è¯„ä¼°

**éªŒæ”¶æ ‡å‡†**:
- å…¨å±€åè°ƒæœ‰æ•ˆæ”¹å–„ç³»ç»Ÿæ•´ä½“æ€§èƒ½
- A/Bæµ‹è¯•å’Œç›‘æ§ç³»ç»Ÿæ­£å¸¸è¿è¡Œ
- è‡ªåŠ¨å›æ»šæœºåˆ¶ç»è¿‡æµ‹è¯•éªŒè¯
- ç”¨æˆ·æ»¡æ„åº¦æŒ‡æ ‡å»ºç«‹å¹¶è¿è¡Œ

### ğŸ”„ ç¬¬å››é˜¶æ®µï¼šæŒç»­ä¼˜åŒ–ä¸æ‰©å±• (æŒç»­è¿›è¡Œ)
**ç›®æ ‡**: ç³»ç»Ÿæ€§èƒ½æŒç»­æ”¹è¿›å’ŒåŠŸèƒ½æ‰©å±•

**ä¸»è¦ä»»åŠ¡**:
1. **æ€§èƒ½è°ƒä¼˜**
   - [ ] ç®—æ³•å‚æ•°ç²¾ç»†è°ƒæ•´
   - [ ] è®¡ç®—æ•ˆç‡ä¼˜åŒ– (ç¼“å­˜ã€å¹¶è¡Œç­‰)
   - [ ] å†…å­˜ä½¿ç”¨ä¼˜åŒ–
   - [ ] æ•°æ®åº“æŸ¥è¯¢ä¼˜åŒ–

2. **åŠŸèƒ½æ‰©å±•**
   - [ ] æ–°å¢å­¦ä¹ ç®—æ³• (Deep RLç­‰)
   - [ ] æ‰©å±•åé¦ˆæ¸ é“ (éšå¼åé¦ˆç­‰)
   - [ ] æ·»åŠ é«˜çº§åˆ†æåŠŸèƒ½
   - [ ] æ”¯æŒæ›´å¤šä¸šåŠ¡åœºæ™¯

3. **ç³»ç»Ÿç»´æŠ¤**
   - [ ] å®šæœŸæ¨¡å‹é‡è®­ç»ƒ
   - [ ] ç³»ç»Ÿå¥åº·æ£€æŸ¥
   - [ ] æ€§èƒ½åŸºå‡†æµ‹è¯•
   - [ ] æŠ€æœ¯å€ºåŠ¡æ¸…ç†

## âš ï¸ é£é™©è¯„ä¼°ä¸ç¼“è§£ç­–ç•¥

### ğŸ”§ æŠ€æœ¯é£é™©
| é£é™©ç±»å‹ | é£é™©æè¿° | å½±å“ç¨‹åº¦ | ç¼“è§£ç­–ç•¥ |
|---------|----------|---------|----------|
| **ç®—æ³•å¤æ‚æ€§** | å¤šæ¨¡å—RLåè°ƒå¤æ‚åº¦é«˜ | é«˜ | åˆ†é˜¶æ®µå®æ–½ï¼Œé€æ­¥å¢åŠ å¤æ‚åº¦ |
| **æ€§èƒ½é£é™©** | RLè®¡ç®—å¼€é”€å½±å“å“åº”æ—¶é—´ | ä¸­ | å¼‚æ­¥å¤„ç†ï¼Œç¼“å­˜ç­–ç•¥ï¼Œæ€§èƒ½ç›‘æ§ |
| **æ•°æ®è´¨é‡** | åé¦ˆæ•°æ®è´¨é‡å½±å“å­¦ä¹ æ•ˆæœ | ä¸­ | æ•°æ®éªŒè¯ï¼Œè´¨é‡è¿‡æ»¤ï¼Œå¤šæºéªŒè¯ |
| **æ¨¡å‹ç¨³å®šæ€§** | åœ¨çº¿å­¦ä¹ å¯èƒ½å¯¼è‡´æ¨¡å‹ä¸ç¨³å®š | é«˜ | æ¸è¿›å¼æ›´æ–°ï¼ŒA/Bæµ‹è¯•ï¼Œå¿«é€Ÿå›æ»š |

### ğŸ’¼ ä¸šåŠ¡é£é™©  
| é£é™©ç±»å‹ | é£é™©æè¿° | å½±å“ç¨‹åº¦ | ç¼“è§£ç­–ç•¥ |
|---------|----------|---------|----------|
| **ç”¨æˆ·ä½“éªŒ** | æ–°ç®—æ³•å¯èƒ½çŸ­æœŸé™ä½å‡†ç¡®æ€§ | é«˜ | A/Bæµ‹è¯•ï¼Œæ¸è¿›å¼éƒ¨ç½²ï¼Œå¿«é€Ÿå›æ»š |
| **ç»´æŠ¤æˆæœ¬** | ç³»ç»Ÿå¤æ‚åº¦å¢åŠ ç»´æŠ¤éš¾åº¦ | ä¸­ | æ¨¡å—åŒ–è®¾è®¡ï¼Œå……åˆ†æ–‡æ¡£ï¼Œè‡ªåŠ¨åŒ–æµ‹è¯• |
| **æŠ€èƒ½ä¾èµ–** | å›¢é˜Ÿéœ€è¦ML/RLä¸“ä¸šæŠ€èƒ½ | ä¸­ | æŠ€èƒ½åŸ¹è®­ï¼Œå¤–éƒ¨å’¨è¯¢ï¼ŒçŸ¥è¯†æ–‡æ¡£åŒ– |

## ğŸ† æ€»ç»“

æœ¬è®¾è®¡æ–‡æ¡£è¯¦ç»†æè¿°äº†MMPç³»ç»ŸåŸºäºå¢å¼ºå­¦ä¹ çš„å…¨é¢å‡çº§æ–¹æ¡ˆã€‚é€šè¿‡ç»Ÿä¸€å­¦ä¹ æ¡†æ¶ï¼Œæˆ‘ä»¬å°†æ™ºèƒ½åˆ†ç±»ã€æ™ºèƒ½åŒ¹é…å’Œå‚æ•°æå–ä¸‰å¤§æ ¸å¿ƒæ¨¡å—æœ‰æœºæ•´åˆï¼Œæ„å»ºäº†ä¸€ä¸ªè‡ªé€‚åº”ã€å¯æŒç»­æ”¹è¿›çš„æ™ºèƒ½å†³ç­–ç³»ç»Ÿã€‚

### ğŸŒŸ å…³é”®åˆ›æ–°ç‚¹ï¼š
1. **ç»Ÿä¸€RLæ¡†æ¶**ï¼šè·¨æ¨¡å—åè°ƒå­¦ä¹ ï¼Œå®ç°å…¨å±€æœ€ä¼˜åŒ–
2. **å¤šç›®æ ‡ä¼˜åŒ–**ï¼šå¹³è¡¡å‡†ç¡®æ€§ã€æ•ˆç‡å’Œç”¨æˆ·æ»¡æ„åº¦  
3. **æ¸è¿›å¼éƒ¨ç½²**ï¼šé™ä½é£é™©ï¼Œç¡®ä¿ç³»ç»Ÿç¨³å®šæ€§
4. **æ™ºèƒ½ç›‘æ§**ï¼šå®æ—¶æ€§èƒ½ç›‘æ§å’Œè‡ªåŠ¨å›æ»šæœºåˆ¶
5. **ç”¨æˆ·ä¸­å¿ƒ**ï¼šä»¥ç”¨æˆ·åé¦ˆä¸ºæ ¸å¿ƒçš„æŒç»­å­¦ä¹ 

### âœ… æ ¸å¿ƒä¼˜åŠ¿ï¼š
- **è‡ªé€‚åº”æ€§å¼º**ï¼šæ ¹æ®ç”¨æˆ·åé¦ˆå’Œç¯å¢ƒå˜åŒ–æŒç»­å­¦ä¹ æ”¹è¿›
- **å¯è§£é‡Šæ€§å¥½**ï¼šç»“åˆè§„åˆ™å¼•æ“å’Œä¼ ç»ŸMLï¼Œä¿æŒå†³ç­–é€æ˜åº¦
- **é²æ£’æ€§é«˜**ï¼šå¤šç®—æ³•é›†æˆå’Œæ™ºèƒ½å›æ»šç¡®ä¿ç³»ç»Ÿç¨³å®š
- **å¯æ‰©å±•æ€§**ï¼šæ¨¡å—åŒ–æ¶æ„ä¾¿äºåŠŸèƒ½æ‰©å±•å’Œç®—æ³•å‡çº§
- **ç”¨æˆ·å‹å¥½**ï¼šæ³¨é‡ç”¨æˆ·ä½“éªŒï¼Œæä¾›ç›´è§‚çš„äº¤äº’ç•Œé¢

### ğŸ“ å®æ–½å»ºè®®ï¼š
1. **åˆ†é˜¶æ®µå®æ–½**ï¼šä»åŸºç¡€æ¶æ„å¼€å§‹ï¼Œé€æ­¥å¢åŠ å¤æ‚åº¦ï¼Œé¿å…å¤§çˆ†ç‚¸å¼å‡çº§
2. **æ•°æ®é©±åŠ¨**ï¼šé‡è§†åé¦ˆæ•°æ®è´¨é‡ï¼Œå»ºç«‹å¤šç»´åº¦è¯„ä¼°ä½“ç³»ï¼Œç¡®ä¿å­¦ä¹ æ•ˆæœ
3. **æŒç»­ç›‘æ§**ï¼šå»ºç«‹å®Œå–„çš„æ€§èƒ½ç›‘æ§å’Œå¿«é€Ÿå“åº”æœºåˆ¶ï¼ŒåŠæ—¶å‘ç°å¹¶è§£å†³é—®é¢˜  
4. **ç”¨æˆ·å‚ä¸**ï¼šé¼“åŠ±ç”¨æˆ·åé¦ˆï¼Œå½¢æˆæœ‰æ•ˆçš„å­¦ä¹ é—­ç¯ï¼Œæå‡ç³»ç»Ÿæ™ºèƒ½åŒ–æ°´å¹³
5. **æŠ€æœ¯å‚¨å¤‡**ï¼šåŸ¹å…»å›¢é˜ŸRLå’ŒMLèƒ½åŠ›ï¼Œå»ºç«‹æŠ€æœ¯æ–‡æ¡£ï¼Œç¡®ä¿æŠ€æœ¯å¯æŒç»­æ€§

é€šè¿‡æœ¬è®¾è®¡æ–¹æ¡ˆçš„å®æ–½ï¼ŒMMPç³»ç»Ÿå°†ä»ä¼ ç»Ÿçš„è§„åˆ™é©±åŠ¨æ¨¡å¼å‡çº§ä¸ºæ™ºèƒ½å­¦ä¹ é©±åŠ¨æ¨¡å¼ï¼Œæ˜¾è‘—æå‡ç³»ç»Ÿçš„æ™ºèƒ½åŒ–æ°´å¹³å’Œç”¨æˆ·ä½“éªŒï¼Œä¸ºæœªæ¥çš„åŠŸèƒ½æ‰©å±•å’ŒæŠ€æœ¯å‡çº§å¥ å®šåšå®åŸºç¡€ã€‚

---

*æ­¤æ–‡æ¡£ä½œä¸ºMMPæ™ºèƒ½åŒ–å‡çº§çš„æŠ€æœ¯æŒ‡å¯¼æ–‡æ¡£ï¼Œå°†éšç€é¡¹ç›®è¿›å±•æŒç»­æ›´æ–°å’Œå®Œå–„ã€‚*  
*æœ€åæ›´æ–°æ—¶é—´: 2025å¹´9æœˆ22æ—¥*  
*æ–‡æ¡£ç‰ˆæœ¬: v2.0 - å…¨æ¨¡å—RLé›†æˆè®¾è®¡*