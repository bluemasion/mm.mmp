# material_recognition_test.py - æè´¨è¯†åˆ«æµ‹è¯•å·¥å…·
import os
import sys
import json
import logging
from typing import List, Dict, Any
import time
from datetime import datetime

# æ·»åŠ appæ¨¡å—è·¯å¾„
sys.path.append(os.path.join(os.path.dirname(__file__), 'app'))

from app.smart_classifier import SmartClassifier, MaterialFeature
from app.enhanced_smart_classifier import EnhancedSmartClassifier

class MaterialRecognitionTester:
    """æè´¨è¯†åˆ«æµ‹è¯•å·¥å…·"""
    
    def __init__(self):
        self.setup_logging()
        
        # æ•°æ®åº“è·¯å¾„
        self.db_path = 'master_data.db'
        if not os.path.exists(self.db_path):
            raise FileNotFoundError(f"æ•°æ®åº“æ–‡ä»¶æœªæ‰¾åˆ°: {self.db_path}")
            
        # åˆå§‹åŒ–åˆ†ç±»å™¨
        self.original_classifier = SmartClassifier(self.db_path)
        self.enhanced_classifier = EnhancedSmartClassifier(self.db_path)
        
    def setup_logging(self):
        """è®¾ç½®æ—¥å¿—"""
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
        )
        self.logger = logging.getLogger(__name__)
        
    def create_test_dataset(self) -> List[Dict[str, Any]]:
        """åˆ›å»ºå…¨é¢çš„æµ‹è¯•æ•°æ®é›†"""
        return [
            # ä¸é”ˆé’¢ç³»åˆ—æµ‹è¯•
            {
                'name': '304ä¸é”ˆé’¢ç–æ°´å™¨',
                'spec': 'DN25 PN16',
                'expected_materials': ['304', 'ä¸é”ˆé’¢'],
                'expected_category': 'ç–æ°´é˜€',
                'difficulty': 'medium'
            },
            {
                'name': '316Lä¸é”ˆé’¢æ³•å…°',
                'spec': 'DN100 PN16',
                'expected_materials': ['316L'],
                'expected_category': 'æ³•å…°',
                'difficulty': 'medium'
            },
            {
                'name': '321ä¸é”ˆé’¢ä¸‰é€š',
                'spec': 'DN50Ã—40Ã—50',
                'expected_materials': ['321'],
                'expected_category': 'ä¸‰é€š',
                'difficulty': 'hard'
            },
            
            # ç¢³é’¢ç³»åˆ—æµ‹è¯•
            {
                'name': 'ç¢³é’¢èºå¡',
                'spec': 'M20Ã—2.5',
                'expected_materials': ['ç¢³é’¢'],
                'expected_category': 'ç´§å›ºä»¶',
                'difficulty': 'easy'
            },
            {
                'name': '20#é’¢ç®¡é“',
                'spec': 'DN80 PN25',
                'expected_materials': ['20#'],
                'expected_category': 'ç®¡é“',
                'difficulty': 'medium'
            },
            {
                'name': 'Q235æ³•å…°',
                'spec': 'DN150 PN16',
                'expected_materials': ['Q235'],
                'expected_category': 'æ³•å…°',
                'difficulty': 'medium'
            },
            
            # æœ‰è‰²é‡‘å±æµ‹è¯•
            {
                'name': 'é»„é“œçƒé˜€',
                'spec': 'DN50 PN16',
                'expected_materials': ['é»„é“œ'],
                'expected_category': 'çƒé˜€',
                'difficulty': 'easy'
            },
            {
                'name': 'ç´«é“œç®¡æ¥å¤´',
                'spec': '1/2"NPT',
                'expected_materials': ['ç´«é“œ'],
                'expected_category': 'æ¥å¤´',
                'difficulty': 'medium'
            },
            
            # è¡¨é¢å¤„ç†æµ‹è¯•
            {
                'name': 'é•€é”Œç®¡æ¥å¤´',
                'spec': '1/2å¯¸',
                'expected_materials': ['é•€é”Œ'],
                'expected_category': 'æ¥å¤´',
                'difficulty': 'medium'
            },
            {
                'name': 'é•€é•èºæ “',
                'spec': 'M16Ã—50',
                'expected_materials': ['é•€é•'],
                'expected_category': 'èºæ “',
                'difficulty': 'hard'
            },
            
            # å¤åˆæè´¨æµ‹è¯•ï¼ˆéš¾åº¦é«˜ï¼‰
            {
                'name': '304ä¸é”ˆé’¢é•€é”Œæ³•å…°',
                'spec': 'DN80 PN16',
                'expected_materials': ['304', 'é•€é”Œ'],
                'expected_category': 'æ³•å…°',
                'difficulty': 'hard'
            },
            
            # æ— æè´¨ä¿¡æ¯æµ‹è¯•ï¼ˆå¯¹ç…§ç»„ï¼‰
            {
                'name': 'ç–æ°´å™¨',
                'spec': 'DN25',
                'expected_materials': [],
                'expected_category': 'ç–æ°´é˜€',
                'difficulty': 'easy'
            },
            {
                'name': 'çƒé˜€',
                'spec': 'DN50',
                'expected_materials': [],
                'expected_category': 'çƒé˜€',
                'difficulty': 'easy'
            }
        ]
        
    def test_single_material(self, test_case: Dict[str, Any]) -> Dict[str, Any]:
        """æµ‹è¯•å•ä¸ªç‰©æ–™çš„è¯†åˆ«æ•ˆæœ"""
        
        material = MaterialFeature(
            name=test_case['name'],
            spec=test_case['spec'],
            unit='ä¸ª'
        )
        
        start_time = time.time()
        
        # åŸå§‹åˆ†ç±»å™¨æµ‹è¯•
        original_results = self.original_classifier.classify_material(material)
        original_time = time.time() - start_time
        
        start_time = time.time()
        
        # å¢å¼ºåˆ†ç±»å™¨æµ‹è¯•  
        enhanced_results = self.enhanced_classifier.classify_material(material)
        enhanced_time = time.time() - start_time
        
        # åˆ†æç»“æœ
        result = {
            'input': {
                'name': test_case['name'],
                'spec': test_case['spec'],
                'difficulty': test_case['difficulty']
            },
            'expected': {
                'materials': test_case['expected_materials'],
                'category': test_case['expected_category']
            },
            'original': {
                'category': original_results[0]['category'] if original_results else 'N/A',
                'confidence': original_results[0]['confidence'] if original_results else 0,
                'time_ms': round(original_time * 1000, 2)
            },
            'enhanced': {
                'category': enhanced_results[0]['category'] if enhanced_results else 'N/A',
                'confidence': enhanced_results[0]['confidence'] if enhanced_results else 0,
                'materials_detected': enhanced_results[0].get('material_info', []) if enhanced_results else [],
                'time_ms': round(enhanced_time * 1000, 2)
            }
        }
        
        # è®¡ç®—æ”¹è¿›æ•ˆæœ
        if original_results and enhanced_results:
            result['improvement'] = {
                'confidence_delta': enhanced_results[0]['confidence'] - original_results[0]['confidence'],
                'category_match': enhanced_results[0]['category'] == test_case['expected_category'],
                'material_detection_success': len(enhanced_results[0].get('material_info', [])) > 0 and len(test_case['expected_materials']) > 0
            }
            
        return result
        
    def run_comprehensive_test(self) -> Dict[str, Any]:
        """è¿è¡Œå…¨é¢æµ‹è¯•"""
        
        print("ğŸ”¬ å¼€å§‹æè´¨è¯†åˆ«å…¨é¢æµ‹è¯•...")
        print("=" * 60)
        
        test_dataset = self.create_test_dataset()
        results = []
        
        for i, test_case in enumerate(test_dataset, 1):
            print(f"\næµ‹è¯• {i}/{len(test_dataset)}: {test_case['name']}")
            result = self.test_single_material(test_case)
            results.append(result)
            
            # æ‰“å°æµ‹è¯•ç»“æœ
            self._print_test_result(result)
            
        # ç»Ÿè®¡åˆ†æ
        stats = self._calculate_statistics(results)
        
        # ç”ŸæˆæŠ¥å‘Š
        report = {
            'test_time': datetime.now().isoformat(),
            'total_tests': len(results),
            'results': results,
            'statistics': stats
        }
        
        return report
        
    def _print_test_result(self, result: Dict[str, Any]):
        """æ‰“å°å•ä¸ªæµ‹è¯•ç»“æœ"""
        
        input_info = result['input']
        original = result['original']
        enhanced = result['enhanced']
        
        print(f"  ğŸ“ è¾“å…¥: {input_info['name']} ({input_info['spec']})")
        print(f"  ğŸ“Š åŸå§‹: {original['category']} ({original['confidence']}%) - {original['time_ms']}ms")
        print(f"  âœ¨ å¢å¼º: {enhanced['category']} ({enhanced['confidence']}%) - {enhanced['time_ms']}ms")
        
        if 'improvement' in result:
            improvement = result['improvement']
            delta = improvement['confidence_delta']
            print(f"  ğŸ¯ æ”¹è¿›: {delta:+.1f}% | åˆ†ç±»æ­£ç¡®: {'âœ…' if improvement['category_match'] else 'âŒ'} | æè´¨æ£€æµ‹: {'âœ…' if improvement['material_detection_success'] else 'âŒ'}")
        else:
            print("  âš ï¸  æ— æ³•æ¯”è¾ƒç»“æœ")
            
    def _calculate_statistics(self, results: List[Dict[str, Any]]) -> Dict[str, Any]:
        """è®¡ç®—ç»Ÿè®¡ä¿¡æ¯"""
        
        stats = {
            'total_tests': len(results),
            'original_algorithm': {
                'avg_confidence': 0,
                'correct_classifications': 0,
                'avg_time_ms': 0
            },
            'enhanced_algorithm': {
                'avg_confidence': 0, 
                'correct_classifications': 0,
                'material_detections': 0,
                'avg_time_ms': 0
            },
            'improvements': {
                'avg_confidence_gain': 0,
                'accuracy_improvement': 0,
                'tests_with_gains': 0
            },
            'difficulty_analysis': {
                'easy': {'total': 0, 'improved': 0},
                'medium': {'total': 0, 'improved': 0},
                'hard': {'total': 0, 'improved': 0}
            }
        }
        
        valid_comparisons = [r for r in results if 'improvement' in r]
        
        if not valid_comparisons:
            return stats
            
        # åŸå§‹ç®—æ³•ç»Ÿè®¡
        original_confidences = [r['original']['confidence'] for r in valid_comparisons]
        original_times = [r['original']['time_ms'] for r in valid_comparisons]
        original_correct = sum(1 for r in valid_comparisons if r['original']['category'] == r['expected']['category'])
        
        stats['original_algorithm']['avg_confidence'] = round(sum(original_confidences) / len(original_confidences), 1)
        stats['original_algorithm']['correct_classifications'] = original_correct
        stats['original_algorithm']['avg_time_ms'] = round(sum(original_times) / len(original_times), 2)
        
        # å¢å¼ºç®—æ³•ç»Ÿè®¡
        enhanced_confidences = [r['enhanced']['confidence'] for r in valid_comparisons]
        enhanced_times = [r['enhanced']['time_ms'] for r in valid_comparisons]
        enhanced_correct = sum(1 for r in valid_comparisons if r['improvement']['category_match'])
        material_detections = sum(1 for r in valid_comparisons if r['improvement']['material_detection_success'])
        
        stats['enhanced_algorithm']['avg_confidence'] = round(sum(enhanced_confidences) / len(enhanced_confidences), 1)
        stats['enhanced_algorithm']['correct_classifications'] = enhanced_correct
        stats['enhanced_algorithm']['material_detections'] = material_detections
        stats['enhanced_algorithm']['avg_time_ms'] = round(sum(enhanced_times) / len(enhanced_times), 2)
        
        # æ”¹è¿›ç»Ÿè®¡
        confidence_gains = [r['improvement']['confidence_delta'] for r in valid_comparisons]
        tests_with_gains = sum(1 for gain in confidence_gains if gain > 0)
        
        stats['improvements']['avg_confidence_gain'] = round(sum(confidence_gains) / len(confidence_gains), 1)
        stats['improvements']['accuracy_improvement'] = enhanced_correct - original_correct
        stats['improvements']['tests_with_gains'] = tests_with_gains
        
        # éš¾åº¦åˆ†æ
        for result in valid_comparisons:
            difficulty = result['input']['difficulty']
            stats['difficulty_analysis'][difficulty]['total'] += 1
            if result['improvement']['confidence_delta'] > 5:  # 5%ä»¥ä¸Šæ”¹è¿›
                stats['difficulty_analysis'][difficulty]['improved'] += 1
                
        return stats
        
    def print_summary_report(self, report: Dict[str, Any]):
        """æ‰“å°æ€»ç»“æŠ¥å‘Š"""
        
        stats = report['statistics']
        
        print("\n" + "=" * 60)
        print("ğŸ“Š æè´¨è¯†åˆ«æµ‹è¯•æ€»ç»“æŠ¥å‘Š")
        print("=" * 60)
        
        print(f"\nğŸ§ª æµ‹è¯•æ¦‚å†µ:")
        print(f"  æ€»æµ‹è¯•æ•°: {stats['total_tests']}")
        print(f"  æµ‹è¯•æ—¶é—´: {report['test_time']}")
        
        print(f"\nğŸ“ˆ åŸå§‹ç®—æ³•è¡¨ç°:")
        print(f"  å¹³å‡ç½®ä¿¡åº¦: {stats['original_algorithm']['avg_confidence']}%")
        print(f"  æ­£ç¡®åˆ†ç±»æ•°: {stats['original_algorithm']['correct_classifications']}/{stats['total_tests']}")
        print(f"  å¹³å‡å“åº”æ—¶é—´: {stats['original_algorithm']['avg_time_ms']}ms")
        
        print(f"\nâœ¨ å¢å¼ºç®—æ³•è¡¨ç°:")
        print(f"  å¹³å‡ç½®ä¿¡åº¦: {stats['enhanced_algorithm']['avg_confidence']}%")
        print(f"  æ­£ç¡®åˆ†ç±»æ•°: {stats['enhanced_algorithm']['correct_classifications']}/{stats['total_tests']}")
        print(f"  æè´¨æ£€æµ‹æ•°: {stats['enhanced_algorithm']['material_detections']}")
        print(f"  å¹³å‡å“åº”æ—¶é—´: {stats['enhanced_algorithm']['avg_time_ms']}ms")
        
        print(f"\nğŸ¯ æ”¹è¿›æ•ˆæœ:")
        print(f"  å¹³å‡ç½®ä¿¡åº¦æå‡: {stats['improvements']['avg_confidence_gain']:+.1f}%")
        print(f"  åˆ†ç±»å‡†ç¡®åº¦æå‡: {stats['improvements']['accuracy_improvement']:+d}")
        print(f"  æœ‰æ”¹è¿›çš„æµ‹è¯•æ•°: {stats['improvements']['tests_with_gains']}/{stats['total_tests']}")
        
        print(f"\nğŸ” éš¾åº¦åˆ†æ:")
        for difficulty, data in stats['difficulty_analysis'].items():
            if data['total'] > 0:
                improvement_rate = (data['improved'] / data['total']) * 100
                print(f"  {difficulty.title()}: {data['improved']}/{data['total']} ({improvement_rate:.1f}%æ”¹è¿›)")
                
    def save_detailed_report(self, report: Dict[str, Any], filename: str = None):
        """ä¿å­˜è¯¦ç»†æŠ¥å‘Šåˆ°JSONæ–‡ä»¶"""
        
        if not filename:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"material_recognition_test_report_{timestamp}.json"
            
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(report, f, ensure_ascii=False, indent=2)
            
        print(f"\nğŸ“„ è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜åˆ°: {filename}")

if __name__ == "__main__":
    # è¿è¡Œæµ‹è¯•
    tester = MaterialRecognitionTester()
    
    try:
        report = tester.run_comprehensive_test()
        tester.print_summary_report(report)
        tester.save_detailed_report(report)
        
        print("\nğŸ‰ æè´¨è¯†åˆ«æµ‹è¯•å®Œæˆï¼")
        
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()